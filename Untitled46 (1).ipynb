{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GA_MVzw3b8bK"
      },
      "outputs": [],
      "source": [
        "%pip install -U -q 'google-genai'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from dataclasses import dataclass, field\n",
        "from typing_extensions import TypedDict, Annotated, Literal"
      ],
      "metadata": {
        "id": "lx1x5gUicnoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "dtpc6ULocUcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "5OLMQWIDcXuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID = \"gemini-2.0-flash\" # @param [\"gemini-1.5-flash-latest\",\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.0-pro-exp-02-05\"] {\"allow-input\":true, isTemplate: true}"
      ],
      "metadata": {
        "id": "GFytSDHScbrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What's the largest planet in our solar system?\"\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "id": "rltTHU5AcewY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass(kw_only=True)\n",
        "class SummaryState:\n",
        "    research_topic: str = field(default=None)\n",
        "    search_query: str = field(default=None)\n",
        "    web_research_results: Annotated[list, operator.add] = field(default_factory=list)\n",
        "    sources_gathered: Annotated[list, operator.add] = field(default_factory=list)\n",
        "    research_loop_count: int = field(default=0)\n",
        "    running_summary: str = field(default=None)"
      ],
      "metadata": {
        "id": "LEmOftWkchI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass(kw_only=True)\n",
        "class SummaryStateInput(TypedDict):\n",
        "    research_topic: str = field(default=None)"
      ],
      "metadata": {
        "id": "Ne4hqQYZck-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass(kw_only=True)\n",
        "class SummaryStateOutput(TypedDict):\n",
        "    running_summary: str = field(default=None)"
      ],
      "metadata": {
        "id": "RN3-xYuEcp7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_writer_instructions = \"\"\"Your goal is to generate a targeted web search query related to financial investments or any finance-related topic specified by the user.\n",
        "\n",
        "<TOPIC>\n",
        "{finance_topic}\n",
        "</TOPIC>\n",
        "\n",
        "<FORMAT>\n",
        "Format your response as a JSON object with ALL three of these exact keys:\n",
        "   - \"query\": The actual search query string\n",
        "   - \"aspect\": The specific aspect of the finance topic being researched\n",
        "   - \"rationale\": Brief explanation of why this query is relevant\n",
        "</FORMAT>\n",
        "\n",
        "<EXAMPLE>\n",
        "Example output:\n",
        "{{\n",
        "    \"query\": \"best index funds for long-term investment 2025\",\n",
        "    \"aspect\": \"investment strategy\",\n",
        "    \"rationale\": \"Identifying top-performing index funds for long-term portfolio growth\"\n",
        "}}\n",
        "</EXAMPLE>\n",
        "\n",
        "Provide your response in JSON format:\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "KP9dqoHhcri9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer_instructions = \"\"\"<GOAL>\n",
        "Generate a high-quality summary of the web search results, focusing on financial investments or the specific finance-related topic requested by the user.\n",
        "</GOAL>\n",
        "\n",
        "<REQUIREMENTS>\n",
        "When creating a NEW summary:\n",
        "1. Highlight the most relevant financial insights, trends, or strategies from the search results.\n",
        "2. Ensure a coherent flow of information while keeping it concise and actionable.\n",
        "\n",
        "When EXTENDING an existing summary:\n",
        "1. Read the existing summary and new search results carefully.\n",
        "2. Compare the new information with the existing summary.\n",
        "3. For each piece of new information:\n",
        "    a. If it builds on an existing point, integrate it smoothly.\n",
        "    b. If it introduces a new relevant aspect, add a separate paragraph.\n",
        "    c. If it’s irrelevant to financial investments, ignore it.\n",
        "4. Ensure all additions align with the user’s finance-related query.\n",
        "5. Verify that the final output differs from the original summary while improving its depth.\n",
        "\n",
        "<FORMATTING>\n",
        "- Start directly with the updated summary, without preamble or titles. Do not use XML tags in the output.\n",
        "</FORMATTING>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "EFWKMWj9c2-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reflection_instructions = \"\"\"You are an expert financial research assistant analyzing a summary about {finance_topic}.\n",
        "\n",
        "<GOAL>\n",
        "1. Identify missing details or areas that need deeper exploration.\n",
        "2. Generate a follow-up question to help expand financial knowledge.\n",
        "3. Focus on investment strategies, market trends, risk factors, regulations, or financial instruments that weren’t fully covered.\n",
        "</GOAL>\n",
        "\n",
        "<REQUIREMENTS>\n",
        "Ensure the follow-up question is self-contained and provides necessary context for a web search.\n",
        "</REQUIREMENTS>\n",
        "\n",
        "<FORMAT>\n",
        "Format your response as a JSON object with these exact keys:\n",
        "- \"knowledge_gap\": Describe what financial information is missing or unclear.\n",
        "- \"follow_up_query\": Write a specific question to address this gap.\n",
        "</FORMAT>\n",
        "\n",
        "<EXAMPLE>\n",
        "Example output:\n",
        "{{\n",
        "    \"knowledge_gap\": \"The summary does not mention tax implications of investing in ETFs vs. mutual funds.\",\n",
        "    \"follow_up_query\": \"What are the tax advantages and disadvantages of ETFs compared to mutual funds?\"\n",
        "}}\n",
        "</EXAMPLE>\n",
        "\n",
        "Provide your analysis in JSON format:\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "F9Xlm4mWc4tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SearchAPI.TAVILY.value"
      ],
      "metadata": {
        "id": "N-VJs5Pzgx2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dataclasses import dataclass, fields\n",
        "from typing import Any, Optional\n",
        "\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from enum import Enum\n",
        "\n",
        "class SearchAPI(Enum):\n",
        "    PERPLEXITY = \"perplexity\"\n",
        "    TAVILY = \"tavily\"\n",
        "    DUCKDUCKGO = \"duckduckgo\"\n",
        "\n",
        "@dataclass(kw_only=True)\n",
        "class Configuration:\n",
        "    \"\"\"The configurable fields for the research assistant.\"\"\"\n",
        "    max_web_research_loops: int = int(os.environ.get(\"MAX_WEB_RESEARCH_LOOPS\", \"3\"))\n",
        "    local_llm: str = MODEL_ID\n",
        "    search_api: SearchAPI = SearchAPI(os.environ.get(\"SEARCH_API\", SearchAPI.TAVILY.value))  # Default to DUCKDUCKGO\n",
        "    fetch_full_page: bool = os.environ.get(\"FETCH_FULL_PAGE\", \"False\").lower() in (\"true\", \"1\", \"t\")\n",
        "    ollama_base_url: str = os.environ.get(\"OLLAMA_BASE_URL\", \"http://localhost:11434/\")\n",
        "\n",
        "    @classmethod\n",
        "    def from_runnable_config(\n",
        "        cls, config: Optional[RunnableConfig] = None\n",
        "    ) -> \"Configuration\":\n",
        "        \"\"\"Create a Configuration instance from a RunnableConfig.\"\"\"\n",
        "        configurable = (\n",
        "            config[\"configurable\"] if config and \"configurable\" in config else {}\n",
        "        )\n",
        "        values: dict[str, Any] = {\n",
        "            f.name: os.environ.get(f.name.upper(), configurable.get(f.name))\n",
        "            for f in fields(cls)\n",
        "            if f.init\n",
        "        }\n",
        "        return cls(**{k: v for k, v in values.items() if v})"
      ],
      "metadata": {
        "id": "la9uDYi6c6Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tavily-python"
      ],
      "metadata": {
        "id": "EsQ76rnPdIPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from typing import Dict, Any, List, Optional\n",
        "from langsmith import traceable\n",
        "from tavily import TavilyClient\n",
        "from duckduckgo_search import DDGS\n",
        "\n",
        "def deduplicate_and_format_sources(search_response, max_tokens_per_source, include_raw_content=False):\n",
        "    \"\"\"\n",
        "    Takes either a single search response or list of responses from search APIs and formats them.\n",
        "    Limits the raw_content to approximately max_tokens_per_source.\n",
        "    include_raw_content specifies whether to include the raw_content from Tavily in the formatted string.\n",
        "\n",
        "    Args:\n",
        "        search_response: Either:\n",
        "            - A dict with a 'results' key containing a list of search results\n",
        "            - A list of dicts, each containing search results\n",
        "\n",
        "    Returns:\n",
        "        str: Formatted string with deduplicated sources\n",
        "    \"\"\"\n",
        "    # Convert input to list of results\n",
        "    if isinstance(search_response, dict):\n",
        "        sources_list = search_response['results']\n",
        "    elif isinstance(search_response, list):\n",
        "        sources_list = []\n",
        "        for response in search_response:\n",
        "            if isinstance(response, dict) and 'results' in response:\n",
        "                sources_list.extend(response['results'])\n",
        "            else:\n",
        "                sources_list.extend(response)\n",
        "    else:\n",
        "        raise ValueError(\"Input must be either a dict with 'results' or a list of search results\")\n",
        "\n",
        "    # Deduplicate by URL\n",
        "    unique_sources = {}\n",
        "    for source in sources_list:\n",
        "        if source['url'] not in unique_sources:\n",
        "            unique_sources[source['url']] = source\n",
        "\n",
        "    # Format output\n",
        "    formatted_text = \"Sources:\\n\\n\"\n",
        "    for i, source in enumerate(unique_sources.values(), 1):\n",
        "        formatted_text += f\"Source {source['title']}:\\n===\\n\"\n",
        "        formatted_text += f\"URL: {source['url']}\\n===\\n\"\n",
        "        formatted_text += f\"Most relevant content from source: {source['content']}\\n===\\n\"\n",
        "        if include_raw_content:\n",
        "            # Using rough estimate of 4 characters per token\n",
        "            char_limit = max_tokens_per_source * 4\n",
        "            # Handle None raw_content\n",
        "            raw_content = source.get('raw_content', '')\n",
        "            if raw_content is None:\n",
        "                raw_content = ''\n",
        "                print(f\"Warning: No raw_content found for source {source['url']}\")\n",
        "            if len(raw_content) > char_limit:\n",
        "                raw_content = raw_content[:char_limit] + \"... [truncated]\"\n",
        "            formatted_text += f\"Full source content limited to {max_tokens_per_source} tokens: {raw_content}\\n\\n\"\n",
        "\n",
        "    return formatted_text.strip()\n",
        "\n",
        "def format_sources(search_results):\n",
        "    \"\"\"Format search results into a bullet-point list of sources.\n",
        "\n",
        "    Args:\n",
        "        search_results (dict): Tavily search response containing results\n",
        "\n",
        "    Returns:\n",
        "        str: Formatted string with sources and their URLs\n",
        "    \"\"\"\n",
        "    return '\\n'.join(\n",
        "        f\"* {source['title']} : {source['url']}\"\n",
        "        for source in search_results['results']\n",
        "    )\n",
        "\n",
        "@traceable\n",
        "def duckduckgo_search(query: str, max_results: int = 3, fetch_full_page: bool = False) -> Dict[str, List[Dict[str, str]]]:\n",
        "    \"\"\"Search the web using DuckDuckGo.\n",
        "\n",
        "    Args:\n",
        "        query (str): The search query to execute\n",
        "        max_results (int): Maximum number of results to return\n",
        "\n",
        "    Returns:\n",
        "        dict: Search response containing:\n",
        "            - results (list): List of search result dictionaries, each containing:\n",
        "                - title (str): Title of the search result\n",
        "                - url (str): URL of the search result\n",
        "                - content (str): Snippet/summary of the content\n",
        "                - raw_content (str): Same as content since DDG doesn't provide full page content\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with DDGS() as ddgs:\n",
        "            results = []\n",
        "            search_results = list(ddgs.text(query, max_results=max_results))\n",
        "\n",
        "            for r in search_results:\n",
        "                url = r.get('href')\n",
        "                title = r.get('title')\n",
        "                content = r.get('body')\n",
        "\n",
        "                if not all([url, title, content]):\n",
        "                    print(f\"Warning: Incomplete result from DuckDuckGo: {r}\")\n",
        "                    continue\n",
        "\n",
        "                raw_content = content\n",
        "                if fetch_full_page:\n",
        "                    try:\n",
        "                        # Try to fetch the full page content using curl\n",
        "                        import urllib.request\n",
        "                        from bs4 import BeautifulSoup\n",
        "\n",
        "                        response = urllib.request.urlopen(url)\n",
        "                        html = response.read()\n",
        "                        soup = BeautifulSoup(html, 'html.parser')\n",
        "                        raw_content = soup.get_text()\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Warning: Failed to fetch full page content for {url}: {str(e)}\")\n",
        "\n",
        "                # Add result to list\n",
        "                result = {\n",
        "                    \"title\": title,\n",
        "                    \"url\": url,\n",
        "                    \"content\": content,\n",
        "                    \"raw_content\": raw_content\n",
        "                }\n",
        "                results.append(result)\n",
        "\n",
        "            return {\"results\": results}\n",
        "    except Exception as e:\n",
        "        print(f\"Error in DuckDuckGo search: {str(e)}\")\n",
        "        print(f\"Full error details: {type(e).__name__}\")\n",
        "        return {\"results\": []}\n",
        "\n",
        "@traceable\n",
        "def tavily_search(query, include_raw_content=True, max_results=3):\n",
        "    \"\"\" Search the web using the Tavily API.\n",
        "\n",
        "    Args:\n",
        "        query (str): The search query to execute\n",
        "        include_raw_content (bool): Whether to include the raw_content from Tavily in the formatted string\n",
        "        max_results (int): Maximum number of results to return\n",
        "\n",
        "    Returns:\n",
        "        dict: Search response containing:\n",
        "            - results (list): List of search result dictionaries, each containing:\n",
        "                - title (str): Title of the search result\n",
        "                - url (str): URL of the search result\n",
        "                - content (str): Snippet/summary of the content\n",
        "                - raw_content (str): Full content of the page if available\"\"\"\n",
        "\n",
        "    api_key = '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'\n",
        "    if not api_key:\n",
        "        raise ValueError(\"TAVILY_API_KEY environment variable is not set\")\n",
        "    tavily_client = TavilyClient(api_key=api_key)\n",
        "    return tavily_client.search(query,\n",
        "                         max_results=max_results,\n",
        "                         include_raw_content=include_raw_content)\n",
        "\n",
        "@traceable\n",
        "def perplexity_search(query: str, perplexity_search_loop_count: int) -> Dict[str, Any]:\n",
        "    \"\"\"Search the web using the Perplexity API.\n",
        "\n",
        "    Args:\n",
        "        query (str): The search query to execute\n",
        "        perplexity_search_loop_count (int): The loop step for perplexity search (starts at 0)\n",
        "\n",
        "    Returns:\n",
        "        dict: Search response containing:\n",
        "            - results (list): List of search result dictionaries, each containing:\n",
        "                - title (str): Title of the search result\n",
        "                - url (str): URL of the search result\n",
        "                - content (str): Snippet/summary of the content\n",
        "                - raw_content (str): Full content of the page if available\n",
        "    \"\"\"\n",
        "\n",
        "    headers = {\n",
        "        \"accept\": \"application/json\",\n",
        "        \"content-type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {os.getenv('PERPLEXITY_API_KEY')}\"\n",
        "    }\n",
        "\n",
        "    payload = {\n",
        "        \"model\": \"sonar-pro\",\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"Search the web and provide factual information with sources.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": query\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    response = requests.post(\n",
        "        \"https://api.perplexity.ai/chat/completions\",\n",
        "        headers=headers,\n",
        "        json=payload\n",
        "    )\n",
        "    response.raise_for_status()  # Raise exception for bad status codes\n",
        "\n",
        "    # Parse the response\n",
        "    data = response.json()\n",
        "    content = data[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "    # Perplexity returns a list of citations for a single search result\n",
        "    citations = data.get(\"citations\", [\"https://perplexity.ai\"])\n",
        "\n",
        "    # Return first citation with full content, others just as references\n",
        "    results = [{\n",
        "        \"title\": f\"Perplexity Search {perplexity_search_loop_count + 1}, Source 1\",\n",
        "        \"url\": citations[0],\n",
        "        \"content\": content,\n",
        "        \"raw_content\": content\n",
        "    }]\n",
        "\n",
        "    # Add additional citations without duplicating content\n",
        "    for i, citation in enumerate(citations[1:], start=2):\n",
        "        results.append({\n",
        "            \"title\": f\"Perplexity Search {perplexity_search_loop_count + 1}, Source {i}\",\n",
        "            \"url\": citation,\n",
        "            \"content\": \"See above for full content\",\n",
        "            \"raw_content\": None\n",
        "        })\n",
        "\n",
        "    return {\"results\": results}"
      ],
      "metadata": {
        "id": "bQkdAMFcdKQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing_extensions import Literal\n",
        "from langchain_core.messages import HumanMessage, SystemMessage  # (Unused now but kept for interface compatibility)\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from langgraph.graph import START, END, StateGraph\n",
        "\n",
        "# Nodes\n",
        "def generate_query(state: SummaryState, config: RunnableConfig):\n",
        "    \"\"\"Generate a query for web search.\"\"\"\n",
        "    # Format the prompt using the correct placeholder\n",
        "    query_writer_instructions_formatted = query_writer_instructions.format(finance_topic=state.research_topic)\n",
        "    prompt = query_writer_instructions_formatted + \"\\nGenerate a query for web search:\"\n",
        "\n",
        "    result = client.models.generate_content(\n",
        "        model=MODEL_ID,\n",
        "        contents=prompt\n",
        "    )\n",
        "\n",
        "    output_text = result.text.strip()\n",
        "    try:\n",
        "        query = json.loads(output_text)\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Error: Could not decode JSON from generate_query. Response was:\", output_text)\n",
        "        # Fallback: Return a default query\n",
        "        query = {\"query\": f\"Tell me more about {state.research_topic}\", \"aspect\": \"\", \"rationale\": \"\"}\n",
        "\n",
        "    return {\"search_query\": query['query']}\n",
        "\n",
        "\n",
        "def web_research(state: SummaryState, config: RunnableConfig):\n",
        "    \"\"\"Gather information from the web.\"\"\"\n",
        "    configurable = Configuration.from_runnable_config(config)\n",
        "\n",
        "    # Determine which search API to use\n",
        "    if isinstance(configurable.search_api, str):\n",
        "        search_api = configurable.search_api\n",
        "    else:\n",
        "        search_api = configurable.search_api.value\n",
        "\n",
        "    if search_api == \"tavily\":\n",
        "        search_results = tavily_search(state.search_query, include_raw_content=True, max_results=1)\n",
        "        search_str = deduplicate_and_format_sources(search_results, max_tokens_per_source=1000, include_raw_content=True)\n",
        "    elif search_api == \"perplexity\":\n",
        "        search_results = perplexity_search(state.search_query, state.research_loop_count)\n",
        "        search_str = deduplicate_and_format_sources(search_results, max_tokens_per_source=1000, include_raw_content=False)\n",
        "    elif search_api == \"duckduckgo\":\n",
        "        search_results = duckduckgo_search(state.search_query, max_results=3, fetch_full_page=configurable.fetch_full_page)\n",
        "        search_str = deduplicate_and_format_sources(search_results, max_tokens_per_source=1000, include_raw_content=True)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported search API: {configurable.search_api}\")\n",
        "\n",
        "    return {\n",
        "        \"sources_gathered\": [format_sources(search_results)],\n",
        "        \"research_loop_count\": state.research_loop_count + 1,\n",
        "        \"web_research_results\": [search_str]\n",
        "    }\n",
        "\n",
        "def summarize_sources(state: SummaryState, config: RunnableConfig):\n",
        "    \"\"\"Summarize the gathered sources.\"\"\"\n",
        "    # Existing summary and most recent search results\n",
        "    existing_summary = state.running_summary\n",
        "    most_recent_web_research = state.web_research_results[-1]\n",
        "\n",
        "    if existing_summary:\n",
        "        human_message_content = (\n",
        "            f\"<User Input> \\n {state.research_topic} \\n <User Input>\\n\\n\"\n",
        "            f\"<Existing Summary> \\n {existing_summary} \\n <Existing Summary>\\n\\n\"\n",
        "            f\"<New Search Results> \\n {most_recent_web_research} \\n <New Search Results>\"\n",
        "        )\n",
        "    else:\n",
        "        human_message_content = (\n",
        "            f\"<User Input> \\n {state.research_topic} \\n <User Input>\\n\\n\"\n",
        "            f\"<Search Results> \\n {most_recent_web_research} \\n <Search Results>\"\n",
        "        )\n",
        "\n",
        "    prompt = summarizer_instructions + \"\\n\" + human_message_content\n",
        "\n",
        "    result = client.models.generate_content(\n",
        "        model=MODEL_ID,\n",
        "        contents=prompt\n",
        "    )\n",
        "    running_summary = result.text\n",
        "\n",
        "    # Remove any unwanted <think> tags\n",
        "    while \"<think>\" in running_summary and \"</think>\" in running_summary:\n",
        "        start = running_summary.find(\"<think>\")\n",
        "        end = running_summary.find(\"</think>\") + len(\"</think>\")\n",
        "        running_summary = running_summary[:start] + running_summary[end:]\n",
        "\n",
        "    return {\"running_summary\": running_summary}\n",
        "\n",
        "def reflect_on_summary(state: SummaryState, config: RunnableConfig):\n",
        "    \"\"\"Reflect on the summary and generate a follow-up query.\"\"\"\n",
        "    prompt = (\n",
        "        reflection_instructions.format(finance_topic=state.research_topic)\n",
        "        + \"\\nIdentify a knowledge gap and generate a follow-up web search query based on our existing knowledge: \"\n",
        "        + state.running_summary\n",
        "    )\n",
        "\n",
        "    result = client.models.generate_content(\n",
        "        model=MODEL_ID,\n",
        "        contents=prompt\n",
        "    )\n",
        "\n",
        "    output_text = result.text.strip()\n",
        "    try:\n",
        "        follow_up_query = json.loads(output_text)\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Error: Could not decode JSON from reflect_on_summary. Response was:\", output_text)\n",
        "        # Fallback: Return a default follow-up query\n",
        "        follow_up_query = {\"follow_up_query\": f\"Tell me more about {state.research_topic}\"}\n",
        "\n",
        "    query = follow_up_query.get('follow_up_query')\n",
        "    if not query:\n",
        "        return {\"search_query\": f\"Tell me more about {state.research_topic}\"}\n",
        "    return {\"search_query\": query}\n",
        "\n",
        "\n",
        "def finalize_summary(state: SummaryState):\n",
        "    \"\"\"Finalize the summary by aggregating all source information.\"\"\"\n",
        "    all_sources = \"\\n\".join(source for source in state.sources_gathered)\n",
        "    state.running_summary = f\"## Summary\\n\\n{state.running_summary}\\n\\n### Sources:\\n{all_sources}\"\n",
        "    return {\"running_summary\": state.running_summary}\n",
        "\n",
        "def route_research(state: SummaryState, config: RunnableConfig) -> Literal[\"finalize_summary\", \"web_research\"]:\n",
        "    \"\"\"Route the research based on the follow-up query.\"\"\"\n",
        "    configurable = Configuration.from_runnable_config(config)\n",
        "    if state.research_loop_count <= configurable.max_web_research_loops:\n",
        "        return \"web_research\"\n",
        "    else:\n",
        "        return \"finalize_summary\"\n",
        "\n",
        "# Build the state graph\n",
        "builder = StateGraph(SummaryState, input=SummaryStateInput, output=SummaryStateOutput, config_schema=Configuration)\n",
        "builder.add_node(\"generate_query\", generate_query)\n",
        "builder.add_node(\"web_research\", web_research)\n",
        "builder.add_node(\"summarize_sources\", summarize_sources)\n",
        "builder.add_node(\"reflect_on_summary\", reflect_on_summary)\n",
        "builder.add_node(\"finalize_summary\", finalize_summary)\n",
        "\n",
        "builder.add_edge(START, \"generate_query\")\n",
        "builder.add_edge(\"generate_query\", \"web_research\")\n",
        "builder.add_edge(\"web_research\", \"summarize_sources\")\n",
        "builder.add_edge(\"summarize_sources\", \"reflect_on_summary\")\n",
        "builder.add_conditional_edges(\"reflect_on_summary\", route_research)\n",
        "builder.add_edge(\"finalize_summary\", END)\n",
        "\n",
        "graph = builder.compile()\n"
      ],
      "metadata": {
        "id": "DQPP25C2dRmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "research_input = SummaryState(research_topic='Best stock to invest in India?')"
      ],
      "metadata": {
        "id": "9VonJmiIeT3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = graph.invoke(research_input)"
      ],
      "metadata": {
        "id": "Jm8EZuymeXUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "Markdown(summary['running_summary'])"
      ],
      "metadata": {
        "id": "_MxN9hxUfPQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fQez6Zjmh5SS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}