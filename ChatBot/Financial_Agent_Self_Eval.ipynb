{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n",
    "import json\n",
    "import getpass\n",
    "import operator\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass, fields\n",
    "from typing import Any, Dict, List, Optional\n",
    "from typing_extensions import TypedDict, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "from langsmith import traceable\n",
    "# IPython for display (if needed)\n",
    "from IPython.display import Image, display, Markdown\n",
    "\n",
    "# Import LangChain and related tools\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableParallel, RunnableLambda, RunnableBranch\n",
    "from langchain_core.tools import tool, StructuredTool\n",
    "from langchain_core import tools  # if needed\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# For financial data via yfinance\n",
    "import yfinance as yf\n",
    "\n",
    "# For web search and HTML parsing\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# For environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# For YouTube video recommendations\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "\n",
    "# For state graph\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from tavily import TavilyClient\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.colors as pc\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "from typing import TypedDict, Annotated, Optional\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model_name='Gemma2-9b-it', api_key=os.getenv('GROQ_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_writer_instruction_web = \"\"\"Your goal is to generate a targeted web search query related to financial investments or any finance-related topic specified by the user.\n",
    "\n",
    "<TOPIC>\n",
    "{finance_topic}\n",
    "</TOPIC>\n",
    "\n",
    "<FORMAT>\n",
    "Format your response as a JSON object with ALL three of these exact keys:\n",
    "   - \"query\": The actual search query string\n",
    "   - \"aspect\": The specific aspect of the finance topic being researched\n",
    "   - \"rationale\": Brief explanation of why this query is relevant\n",
    "</FORMAT>\n",
    "\n",
    "<EXAMPLE>\n",
    "Example output:\n",
    "{{\n",
    "    \"query\": \"best index funds for long-term investment 2025\",\n",
    "    \"aspect\": \"investment strategy\",\n",
    "    \"rationale\": \"Identifying top-performing index funds for long-term portfolio growth\"\n",
    "}}\n",
    "</EXAMPLE>\n",
    "\n",
    "Provide your response in JSON format:\n",
    "\"\"\"\n",
    "\n",
    "summarizer_instruction_web = \"\"\"<GOAL>\n",
    "Generate a high-quality summary of the web search results, focusing on financial investments or the specific finance-related topic requested by the user. REMEMBER TO ANSWER IN {language} LANGUAGE.\n",
    "</GOAL>\n",
    "\n",
    "<REQUIREMENTS>\n",
    "When creating a NEW summary:\n",
    "1. Highlight the most relevant financial insights, trends, or strategies from the search results.\n",
    "2. Ensure a coherent flow of information while keeping it concise and actionable.\n",
    "\n",
    "When EXTENDING an existing summary:\n",
    "1. Read the existing summary and new search results carefully.\n",
    "2. Compare the new information with the existing summary.\n",
    "3. For each piece of new information:\n",
    "    a. If it builds on an existing point, integrate it smoothly.\n",
    "    b. If it introduces a new relevant aspect, add a separate paragraph.\n",
    "    c. If it’s irrelevant to financial investments, ignore it.\n",
    "4. Ensure all additions align with the user’s finance-related query.\n",
    "5. Verify that the final output differs from the original summary while improving its depth.\n",
    "\n",
    "<FORMATTING>\n",
    "- Start directly with the updated summary, without preamble or titles. Do not use XML tags in the output.\n",
    "</FORMATTING>\n",
    "\"\"\"\n",
    "\n",
    "reflection_instructions_web = \"\"\"You are an expert financial research assistant analyzing a summary about {finance_topic}.\n",
    "\n",
    "<GOAL>\n",
    "1. Identify missing details or areas that need deeper exploration.\n",
    "2. Generate a follow-up question to help expand financial knowledge.\n",
    "3. Focus on investment strategies, market trends, risk factors, regulations, or financial instruments that weren’t fully covered.\n",
    "</GOAL>\n",
    "\n",
    "<REQUIREMENTS>\n",
    "Ensure the follow-up question is self-contained and provides necessary context for a web search.\n",
    "</REQUIREMENTS>\n",
    "\n",
    "<FORMAT>\n",
    "Format your response as a JSON object with these exact keys:\n",
    "- \"knowledge_gap\": Describe what financial information is missing or unclear.\n",
    "- \"follow_up_query\": Write a specific question to address this gap.\n",
    "</FORMAT>\n",
    "\n",
    "<EXAMPLE>\n",
    "Example output:\n",
    "{{\n",
    "    \"knowledge_gap\": \"The summary does not mention tax implications of investing in ETFs vs. mutual funds.\",\n",
    "    \"follow_up_query\": \"What are the tax advantages and disadvantages of ETFs compared to mutual funds?\"\n",
    "}}\n",
    "</EXAMPLE>\n",
    "\n",
    "Provide your analysis in JSON format:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    route: Literal['Web_query', 'Normal_query', 'Financial_Analysis', 'YouTube_Recommender', 'Plot_Graph'] = Field(None)\n",
    "    research_topic: str\n",
    "    search_query: str\n",
    "    web_research_results: List[str]\n",
    "    sources_gathered: List[str]\n",
    "    research_loop_count: int\n",
    "    running_summary: str\n",
    "    image: list[str]\n",
    "    image_processed: bool\n",
    "    messages: List[Any]  # This will continue to be the working messages (possibly enhanced)\n",
    "    original_messages: List[Any]  # New field to store original messages\n",
    "    plot_type: Optional[str]\n",
    "    ticker: Optional[str]\n",
    "    plot_json: Optional[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stock_data(ticker, period=\"1y\"):\n",
    "    stock = yf.Ticker(ticker)\n",
    "    return stock.history(period=period)\n",
    "\n",
    "def fetch_balance(ticker, tp=\"Annual\"):\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    bs = ticker_obj.balance_sheet if tp == \"Annual\" else ticker_obj.quarterly_balance_sheet\n",
    "    return bs.loc[:, bs.isna().mean() < 0.5]\n",
    "\n",
    "# Plotting functions\n",
    "def plot_candles_stick(df, title=\"\"):\n",
    "    fig = go.Figure(data=[go.Candlestick(x=df.index,\n",
    "                open=df['Open'],\n",
    "                high=df['High'],\n",
    "                low=df['Low'],\n",
    "                close=df['Close'])])\n",
    "    fig.update_layout(title=title)\n",
    "    return fig\n",
    "\n",
    "def plot_balance(df, ticker=\"\", currency=\"\"):\n",
    "    df.columns = pd.to_datetime(df.columns).strftime('%b %d, %Y')\n",
    "    components = {\n",
    "        'Total Assets': {'color': 'forestgreen', 'name': 'Assets'},\n",
    "        'Stockholders Equity': {'color': 'CornflowerBlue', 'name': \"Stockholder's Equity\"},\n",
    "        'Total Liabilities Net Minority Interest': {'color': 'tomato', 'name': \"Total Liabilities\"},\n",
    "    }\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    for component in components:\n",
    "        if component == 'Total Assets':\n",
    "            fig.add_trace(go.Bar(\n",
    "                x=[df.columns, ['Assets'] * len(df.columns)],\n",
    "                y=df.loc[component],\n",
    "                name=components[component]['name'],\n",
    "                marker=dict(color=components[component]['color'])\n",
    "            ))\n",
    "        else:\n",
    "            fig.add_trace(go.Bar(\n",
    "                x=[df.columns, ['L+E'] * len(df.columns)],\n",
    "                y=df.loc[component],\n",
    "                name=components[component]['name'],\n",
    "                marker=dict(color=components[component]['color'])\n",
    "            ))\n",
    "\n",
    "    offset = 0.03 * df.loc['Total Assets'].max()\n",
    "    for i, date in enumerate(df.columns):\n",
    "        fig.add_annotation(\n",
    "            x=[date, \"Assets\"],\n",
    "            y=df.loc['Total Assets', date] / 2,\n",
    "            text=str(round(df.loc['Total Assets', date] / 1e9, 1)) + 'B',\n",
    "            showarrow=False,\n",
    "            font=dict(size=12, color=\"black\"),\n",
    "            align=\"center\"\n",
    "        )\n",
    "        percentage = round((df.loc['Total Liabilities Net Minority Interest', date] / df.loc['Total Assets', date]) * 100, 1)\n",
    "        fig.add_annotation(\n",
    "            x=[date, \"L+E\"],\n",
    "            y=df.loc['Stockholders Equity', date] + df.loc['Total Liabilities Net Minority Interest', date] / 2,\n",
    "            text=str(percentage) + '%',\n",
    "            showarrow=False,\n",
    "            font=dict(size=12, color=\"black\"),\n",
    "            align=\"center\"\n",
    "        )\n",
    "        if i > 0:\n",
    "            percentage = round((df.loc['Total Assets'].iloc[i] / df.loc['Total Assets'].iloc[i - 1] - 1) * 100, 1)\n",
    "            sign = '+' if percentage >= 0 else ''\n",
    "            fig.add_annotation(\n",
    "                x=[date, \"Assets\"],\n",
    "                y=df.loc['Total Assets', date] + offset,\n",
    "                text=sign + str(percentage) + '%',\n",
    "                showarrow=False,\n",
    "                font=dict(size=12, color=\"black\"),\n",
    "                align=\"center\"\n",
    "            )\n",
    "\n",
    "    fig.update_layout(\n",
    "        barmode='stack',\n",
    "        title=f'Accounting Balance: {ticker}',\n",
    "        xaxis_title='Year',\n",
    "        yaxis_title=f'Amount (in {currency})',\n",
    "        legend_title='Balance components',\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "def plot_assets(df, ticker=\"\", currency=\"\"):\n",
    "    assets = {\n",
    "        'Current Assets': {\n",
    "            'Cash Cash Equivalents And Short Term Investments': {},\n",
    "            'Receivables': {},\n",
    "            'Prepaid Assets': None,\n",
    "            'Inventory': {},\n",
    "            'Hedging Assets Current': None,\n",
    "            'Other Current Assets': None\n",
    "        },\n",
    "        'Total Non Current Assets': {\n",
    "            'Net PPE': {},\n",
    "            'Goodwill And Other Intangible Assets': {},\n",
    "            'Investments And Advances': {},\n",
    "            'Investment Properties': None,\n",
    "            'Other Non Current Assets': None\n",
    "        }\n",
    "    }\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        shared_yaxes=True,\n",
    "        horizontal_spacing=0.05,\n",
    "        subplot_titles=['Current Assets', 'Non-Current Assets']\n",
    "    )\n",
    "\n",
    "    colors = pc.sequential.Blugrn[::-1]\n",
    "    i = 0\n",
    "    for component in assets['Current Assets']:\n",
    "        if component in df.index:\n",
    "            fig.add_trace(go.Bar(\n",
    "                x=df.columns,\n",
    "                y=df.loc[component],\n",
    "                name=component,\n",
    "                marker=dict(color=colors[i]),\n",
    "                legendgroup='Current Assets',\n",
    "                showlegend=True\n",
    "            ), row=1, col=1)\n",
    "            i += 1\n",
    "\n",
    "    colors = pc.sequential.Purp[::-1]\n",
    "    i = 0\n",
    "    for component in assets['Total Non Current Assets']:\n",
    "        if component in df.index:\n",
    "            fig.add_trace(go.Bar(\n",
    "                x=df.columns,\n",
    "                y=df.loc[component],\n",
    "                name=component,\n",
    "                marker=dict(color=colors[i]),\n",
    "                legendgroup='Non-current Assets',\n",
    "                showlegend=True\n",
    "            ), row=1, col=2)\n",
    "            i += 1\n",
    "\n",
    "    offset = 0.03 * max(df.loc['Current Assets'].max(), df.loc['Total Non Current Assets'].max())\n",
    "    for i, date in enumerate(df.columns):\n",
    "        fig.add_annotation(\n",
    "            x=date,\n",
    "            y=df.loc['Current Assets', date] + offset,\n",
    "            text=str(round(df.loc['Current Assets', date] / 1e9, 1)) + 'B',\n",
    "            showarrow=False,\n",
    "            font=dict(size=12, color=\"black\"),\n",
    "            align=\"center\",\n",
    "            row=1, col=1\n",
    "        )\n",
    "        fig.add_annotation(\n",
    "            x=date,\n",
    "            y=df.loc['Total Non Current Assets', date] + offset,\n",
    "            text=str(round(df.loc['Total Non Current Assets', date] / 1e9, 1)) + 'B',\n",
    "            showarrow=False,\n",
    "            font=dict(size=12, color=\"black\"),\n",
    "            align=\"center\",\n",
    "            row=1, col=2\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        barmode='stack',\n",
    "        title=f'Assets: {ticker}',\n",
    "        xaxis1=dict(title='Date', type='date', tickvals=df.columns),\n",
    "        xaxis2=dict(title='Date', type='date', tickvals=df.columns),\n",
    "        yaxis_title=f'Amount (in {currency})',\n",
    "        legend_title='Asset Components',\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_query(state: State) -> State:\n",
    "    \"\"\"Parse the user query to determine plot type and ticker\"\"\"\n",
    "    query = state[\"research_topic\"].lower()\n",
    "    #print(query)\n",
    "    ticker = query.split()[-1].upper()\n",
    "    #print(ticker)\n",
    "    if \"candlestick chart\" in query:\n",
    "        return {\"plot_type\": \"candlestick\", \"ticker\": ticker}\n",
    "    elif \"balance sheet\" in query:\n",
    "        return {\"plot_type\": \"balance\", \"ticker\": ticker}\n",
    "    elif \"assets\" in query:\n",
    "        return {\"plot_type\": \"assets\", \"ticker\": ticker}\n",
    "    else:\n",
    "        return {\"plot_type\": None, \"ticker\": None}\n",
    "    \n",
    "def generate_plot(state: State) -> State:\n",
    "    \"\"\"Generate the appropriate plot based on the parsed query\"\"\"\n",
    "    if not state[\"plot_type\"] or not state[\"ticker\"]:\n",
    "        return {\"response\": \"I can generate candlestick charts, balance sheets, or assets visualizations. Please specify what you'd like to see (e.g., 'Show me a candlestick chart for AAPL')\"}\n",
    "    \n",
    "    ticker = state[\"ticker\"]\n",
    "    plot_type = state[\"plot_type\"]\n",
    "    \n",
    "    try:\n",
    "        if plot_type == \"candlestick\":\n",
    "            df = fetch_stock_data(ticker)\n",
    "            fig = plot_candles_stick(df, title=f\"{ticker} Candlestick Chart\")\n",
    "        elif plot_type == \"balance\":\n",
    "            df = fetch_balance(ticker)\n",
    "            fig = plot_balance(df, ticker=ticker, currency=\"INR\")\n",
    "        elif plot_type == \"assets\":\n",
    "            df = fetch_balance(ticker)\n",
    "            fig = plot_assets(df, ticker=ticker, currency=\"INR\")\n",
    "        \n",
    "        plot_json = fig.to_json()\n",
    "        return {\"plot_json\": plot_json}\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\"response\": f\"Error generating plot: {str(e)}\"}\n",
    "    \n",
    "def format_response(state: State) -> State:\n",
    "    \"\"\"Format the final response\"\"\"\n",
    "    print(state.get('plot_json'))\n",
    "    if state.get(\"plot_json\"):\n",
    "        fig = pio.from_json(state.get(\"plot_json\"))\n",
    "        fig.show()\n",
    "        return {\"response\": state[\"plot_json\"]}\n",
    "    elif state.get(\"response\"):\n",
    "        return {\"response\": state[\"response\"]}\n",
    "    else:\n",
    "        return {\"response\": \"Something went wrong while processing your request\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initial_state(user_query: str, image: list[str] = []) -> State:\n",
    "    return {\n",
    "        \"route\": None,\n",
    "        \"research_topic\": user_query,\n",
    "        \"search_query\": \"\",\n",
    "        \"web_research_results\": [],\n",
    "        \"sources_gathered\": [],\n",
    "        \"research_loop_count\": 0,\n",
    "        \"running_summary\": \"\",\n",
    "        \"image\": image,\n",
    "        \"image_processed\": False,\n",
    "        \"messages\": [HumanMessage(content=user_query)],  # Working messages\n",
    "        \"original_messages\": [HumanMessage(content=user_query)],  # Store original message\n",
    "        \"plot_type\": None,\n",
    "        \"ticker\": None,\n",
    "        \"plot_json\": None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Route_First_Step(BaseModel):\n",
    "    # Updated to include YouTube_Recommender\n",
    "    step: Literal['Web_query', 'Normal_query', 'Financial_Analysis', 'YouTube_Recommender','Plot_Graph'] = Field(\n",
    "        None,\n",
    "        description='Determine whether to perform a web search, answer a normal question, perform a financial analysis, recommend YouTube videos or plot graphs.'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchAPI(Enum):\n",
    "    PERPLEXITY = \"perplexity\"\n",
    "    TAVILY = \"tavily\"\n",
    "    DUCKDUCKGO = \"duckduckgo\"\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class Configuration:\n",
    "    max_web_research_loops: int = int(os.environ.get(\"MAX_WEB_RESEARCH_LOOPS\", \"3\"))\n",
    "    search_api: SearchAPI = SearchAPI(os.environ.get(\"SEARCH_API\", \"tavily\"))\n",
    "    fetch_full_page: bool = os.environ.get(\"FETCH_FULL_PAGE\", \"False\").lower() in (\"true\", \"1\", \"t\")\n",
    "    ollama_base_url: str = os.environ.get(\"OLLAMA_BASE_URL\", \"http://localhost:11434/\")\n",
    "\n",
    "    @classmethod\n",
    "    def from_runnable_config(cls, config: Optional[RunnableConfig] = None) -> \"Configuration\":\n",
    "        configurable = config[\"configurable\"] if config and \"configurable\" in config else {}\n",
    "        values: dict[str, Any] = {\n",
    "            f.name: os.environ.get(f.name.upper(), configurable.get(f.name))\n",
    "            for f in fields(cls)\n",
    "            if f.init\n",
    "        }\n",
    "        return cls(**{k: v for k, v in values.items() if v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "def tavily_search(query, include_raw_content=True, max_results=3):\n",
    "    api_key = os.environ['TAVILY_API_KEY']\n",
    "    if not api_key:\n",
    "        raise ValueError(\"TAVILY_API_KEY environment variable is not set\")\n",
    "    tavily_client = TavilyClient(api_key=api_key)\n",
    "    return tavily_client.search(query, max_results=max_results, include_raw_content=include_raw_content)\n",
    "\n",
    "def deduplicate_and_format_sources(search_response, max_tokens_per_source, include_raw_content=False):\n",
    "    if isinstance(search_response, dict):\n",
    "        sources_list = search_response['results']\n",
    "    elif isinstance(search_response, list):\n",
    "        sources_list = []\n",
    "        for response in search_response:\n",
    "            if isinstance(response, dict) and 'results' in response:\n",
    "                sources_list.extend(response['results'])\n",
    "            else:\n",
    "                sources_list.extend(response)\n",
    "    else:\n",
    "        raise ValueError(\"Input must be either a dict with 'results' or a list of search results\")\n",
    "\n",
    "    unique_sources = {}\n",
    "    for source in sources_list:\n",
    "        if source['url'] not in unique_sources:\n",
    "            unique_sources[source['url']] = source\n",
    "\n",
    "    formatted_text = \"Sources:\\n\\n\"\n",
    "    for source in unique_sources.values():\n",
    "        formatted_text += f\"Source {source['title']}:\\n===\\n\"\n",
    "        formatted_text += f\"URL: {source['url']}\\n===\\n\"\n",
    "        formatted_text += f\"Most relevant content from source: {source['content']}\\n===\\n\"\n",
    "        if include_raw_content:\n",
    "            char_limit = max_tokens_per_source * 4\n",
    "            raw_content = source.get('raw_content', '') or ''\n",
    "            if len(raw_content) > char_limit:\n",
    "                raw_content = raw_content[:char_limit] + \"... [truncated]\"\n",
    "            formatted_text += f\"Full source content limited to {max_tokens_per_source} tokens: {raw_content}\\n\\n\"\n",
    "\n",
    "    return formatted_text.strip()\n",
    "\n",
    "def format_sources(search_results):\n",
    "    return '\\n'.join(\n",
    "        f\"* {source['title']} : {source['url']}\"\n",
    "        for source in search_results['results']\n",
    "    )\n",
    "\n",
    "def generate_query(state: State, config: RunnableConfig):\n",
    "    prompt = query_writer_instruction_web.format(finance_topic=state[\"research_topic\"]) + \"\\nGenerate a query for web search:\"\n",
    "    result = llm.invoke(prompt)\n",
    "    output_text = result.content.strip()\n",
    "    try:\n",
    "        query_data = json.loads(output_text)\n",
    "        return {\"search_query\": query_data['query']}\n",
    "    except (json.JSONDecodeError, KeyError) as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        return {\"search_query\": f\"comprehensive analysis of {state['research_topic']}\"}\n",
    "\n",
    "def web_research(state: State, config: RunnableConfig):\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    search_api = configurable.search_api.value if isinstance(configurable.search_api, Enum) is False else configurable.search_api.value\n",
    "    if search_api == \"tavily\":\n",
    "        search_results = tavily_search(state[\"search_query\"], include_raw_content=True, max_results=1)\n",
    "        search_str = deduplicate_and_format_sources(search_results, max_tokens_per_source=1000, include_raw_content=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported search API: {configurable.search_api}\")\n",
    "    return {\n",
    "        \"sources_gathered\": [format_sources(search_results)],\n",
    "        \"research_loop_count\": state[\"research_loop_count\"] + 1,\n",
    "        \"web_research_results\": [search_str]\n",
    "    }\n",
    "\n",
    "def summarize_sources(state: State, config: RunnableConfig):\n",
    "    existing_summary = state['running_summary']\n",
    "    most_recent_web_research = state['web_research_results'][-1]\n",
    "    if existing_summary:\n",
    "        human_message_content = (\n",
    "            f\"<User Input> \\n {state['research_topic']} \\n <User Input>\\n\\n\"\n",
    "            f\"<Existing Summary> \\n {existing_summary} \\n <Existing Summary>\\n\\n\"\n",
    "            f\"<New Search Results> \\n {most_recent_web_research} \\n <New Search Results>\"\n",
    "        )\n",
    "    else:\n",
    "        human_message_content = (\n",
    "            f\"<User Input> \\n {state['research_topic']} \\n <User Input>\\n\\n\"\n",
    "            f\"<Search Results> \\n {most_recent_web_research} \\n <Search Results>\"\n",
    "        )\n",
    "    prompt = summarizer_instruction_web + \"\\n\" + human_message_content\n",
    "    result = llm.invoke(prompt)\n",
    "    running_summary = result.content\n",
    "    while \"<think>\" in running_summary and \"</think>\" in running_summary:\n",
    "        start = running_summary.find(\"<think>\")\n",
    "        end = running_summary.find(\"</think>\") + len(\"</think>\")\n",
    "        running_summary = running_summary[:start] + running_summary[end:]\n",
    "    return {\"running_summary\": running_summary}\n",
    "\n",
    "def reflect_on_summary(state: State, config: RunnableConfig):\n",
    "    prompt = reflection_instructions_web.format(finance_topic=state['research_topic']) \\\n",
    "             + \"\\nIdentify a knowledge gap and generate a follow-up web search query based on our existing knowledge: \" \\\n",
    "             + state['running_summary']\n",
    "    result = llm.invoke(prompt)\n",
    "    output_text = result.content.strip()\n",
    "    try:\n",
    "        follow_up_query = json.loads(output_text)\n",
    "    except json.JSONDecodeError:\n",
    "        #print(\"Error: Could not decode JSON from reflect_on_summary. Response was:\", output_text)\n",
    "        follow_up_query = {\"follow_up_query\": f\"Tell me more about {state['research_topic']}\"}\n",
    "    query = follow_up_query.get('follow_up_query')\n",
    "    if not query:\n",
    "        return {\"search_query\": f\"Tell me more about {state['research_topic']}\"}\n",
    "    return {\"search_query\": query}\n",
    "\n",
    "def finalize_summary(state: State):\n",
    "    all_sources = \"\\n\".join(source for source in state['sources_gathered'])\n",
    "    final_summary = f\"## Web Research Summary\\n\\n{state['running_summary']}\\n\\n### Sources:\\n{all_sources}\"\n",
    "    final_message = HumanMessage(content=final_summary)\n",
    "    return {\n",
    "        \"running_summary\": final_summary,\n",
    "        \"messages\": [final_message],\n",
    "        \"original_messages\": state[\"original_messages\"]  # Preserve original messages\n",
    "    }\n",
    "\n",
    "def route_research(state: State, config: RunnableConfig) -> Literal[\"finalize_summary\", \"web_research\"]:\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    if state['research_loop_count'] < configurable.max_web_research_loops:\n",
    "        return \"web_research\"\n",
    "    return \"finalize_summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def company_address(ticker: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns company address for input ticker.\n",
    "    e.g. company_address: AAPL\n",
    "    Returns company address for ticker AAPL which is stock ticker for Apple Inc.\n",
    "    \"\"\"\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    info = ticker_obj.get_info()\n",
    "\n",
    "    return \" \".join([info[key] for key in ['address1','city','state','zip','country']])\n",
    "\n",
    "@tool\n",
    "def fulltime_employees(ticker: str) -> int:\n",
    "    \"\"\"\n",
    "    Returns fulltime employees count for input ticker.\n",
    "    e.g. company_address: MSFT\n",
    "    Returns fulltime employees count for ticker MSFT which is stock ticker for Microsoft.\n",
    "    \"\"\"\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    info = ticker_obj.get_info()\n",
    "\n",
    "    return info['fullTimeEmployees']\n",
    "\n",
    "@tool\n",
    "def last_close_price(ticker: str) -> float:\n",
    "    \"\"\"\n",
    "    Returns last close price for input ticker.\n",
    "    e.g. company_address: MSFT\n",
    "    Returns last close price for ticker MSFT which is stock ticker for Microsoft.\n",
    "    \"\"\"\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    info = ticker_obj.get_info()\n",
    "\n",
    "    return info['previousClose']\n",
    "\n",
    "@tool\n",
    "def EBITDA(ticker: str) -> float:\n",
    "    \"\"\"\n",
    "    Returns EBITDA for input ticker.\n",
    "    e.g. company_address: AAPL\n",
    "    Returns EBITDA for ticker AAPL which is stock ticker for Apple Inc.\n",
    "    \"\"\"\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    info = ticker_obj.get_info()\n",
    "\n",
    "    return info['ebitda']\n",
    "\n",
    "@tool\n",
    "def total_debt(ticker: str) -> float:\n",
    "    \"\"\"\n",
    "    Returns total debt for input ticker.\n",
    "    e.g. company_address: AAPL\n",
    "    Returns total debt for ticker AAPL which is stock ticker for Apple Inc.\n",
    "    \"\"\"\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    info = ticker_obj.get_info()\n",
    "\n",
    "    return info['totalDebt']\n",
    "\n",
    "@tool\n",
    "def total_revenue(ticker: str) -> float:\n",
    "    \"\"\"\n",
    "    Returns total revenue for input ticker.\n",
    "    e.g. company_address: MSFT\n",
    "    Returns total revenue for ticker MSFT which is stock ticker for Microsoft.\n",
    "    \"\"\"\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    info = ticker_obj.get_info()\n",
    "\n",
    "    return info['totalRevenue']\n",
    "\n",
    "@tool\n",
    "def debt_to_equity_ratio(ticker: str) -> float:\n",
    "    \"\"\"\n",
    "    Returns debt to equity ratio for input ticker.\n",
    "    e.g. company_address: AAPL\n",
    "    Returns debt to equity ratio for ticker AAPL which is stock ticker for Apple Inc.\n",
    "    \"\"\"\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    info = ticker_obj.get_info()\n",
    "\n",
    "    return info['debtToEquity']\n",
    "\n",
    "finance_tools = [\n",
    "    company_address,\n",
    "    fulltime_employees,\n",
    "    last_close_price,\n",
    "    EBITDA,\n",
    "    total_debt,\n",
    "    total_revenue,\n",
    "    debt_to_equity_ratio\n",
    "]\n",
    "finance_tool_map = {t.name: t for t in finance_tools}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_normal = llm\n",
    "normal_query_prompt = \"\"\"\n",
    "You are a financial analyst. Please answer the user's question based on what you know, don't make up anything. REMEMBER TO ANSWER IN {language} LANGUAGE.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_normal_query(state: State):\n",
    "    messages = state.get('messages', [])\n",
    "    system_message = SystemMessage(content=normal_query_prompt + \"\\nFormat your response in Markdown.\")\n",
    "    response = llm_normal.invoke([system_message] + messages)\n",
    "    markdown_response = f\"## Normal Query Response\\n\\n{response.content}\"\n",
    "    return {\n",
    "        \"running_summary\": markdown_response,\n",
    "        \"messages\": [HumanMessage(content=markdown_response)],\n",
    "        \"original_messages\": state[\"original_messages\"]  # Preserve original messages\n",
    "    }\n",
    "llm_financial_analysis = llm.bind_tools(finance_tools, tool_choice='auto')\n",
    "financial_analysis_prompt = \"\"\"\n",
    "You are a financial analyst. You are given tools for accurate data.\n",
    "\"\"\"\n",
    "\n",
    "def call_llm(state: State):\n",
    "    messages = state['messages']\n",
    "    system_prompt = financial_analysis_prompt + \"\\nFormat your response in Markdown.\"\n",
    "    messages = [SystemMessage(content=system_prompt)] + messages\n",
    "    message = llm_financial_analysis.invoke(messages)\n",
    "    return {'messages': [message]}\n",
    "\n",
    "def exists_action(state: State):\n",
    "    result = state['messages'][-1]\n",
    "    return len(result.tool_calls) > 0\n",
    "\n",
    "def take_action(state: State):\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    tool_results = []\n",
    "    for t in tool_calls:\n",
    "        try:\n",
    "            tool_func = finance_tool_map[t['name']]\n",
    "            result = tool_func.invoke(t['args'])\n",
    "        except KeyError:\n",
    "            result = f\"Error: Tool {t['name']} not found\"\n",
    "        except Exception as e:\n",
    "            result = f\"Error executing tool: {str(e)}\"\n",
    "        tool_results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "    markdown_output = \"## Financial Analysis Results\\n\\n\"\n",
    "    for result in tool_results:\n",
    "        markdown_output += f\"### {result.name.replace('_', ' ').title()}\\n\\n{result.content}\\n\\n\"\n",
    "    return {'messages': tool_results, 'running_summary': markdown_output}\n",
    "\n",
    "def format_financial_analysis(state: State):\n",
    "    messages = state['messages']\n",
    "    tool_results = [msg for msg in messages if isinstance(msg, ToolMessage)]\n",
    "    if tool_results:\n",
    "        markdown_output = \"## Financial Analysis Results\\n\\n\"\n",
    "        for result in tool_results:\n",
    "            markdown_output += f\"### {result.name.replace('_', ' ').title()}\\n\\n{result.content}\\n\\n\"\n",
    "    else:\n",
    "        markdown_output = f\"## Financial Analysis\\n\\n{messages[-1].content}\"\n",
    "    return {\"running_summary\": markdown_output, \"messages\": [HumanMessage(content=markdown_output)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YouTubeVideoRecommender:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "    \n",
    "    def get_channel_id(self, channel_name):\n",
    "        request = self.youtube.search().list(\n",
    "            part=\"snippet\",\n",
    "            q=channel_name,\n",
    "            type=\"channel\",\n",
    "            maxResults=1\n",
    "        )\n",
    "        response = request.execute()\n",
    "        if response['items']:\n",
    "            return response['items'][0]['id']['channelId']\n",
    "        return None\n",
    "    \n",
    "    def search_videos_in_channel(self, channel_id, query, max_results=10):\n",
    "        request = self.youtube.search().list(\n",
    "            part=\"snippet\",\n",
    "            channelId=channel_id,\n",
    "            q=query,\n",
    "            type=\"video\",\n",
    "            maxResults=max_results\n",
    "        )\n",
    "        response = request.execute()\n",
    "        videos = []\n",
    "        for item in response['items']:\n",
    "            video_id = item['id']['videoId']\n",
    "            title = item['snippet']['title']\n",
    "            description = item['snippet']['description']\n",
    "            published_at = item['snippet']['publishedAt']\n",
    "            thumbnail = item['snippet']['thumbnails']['high']['url']\n",
    "            channel_title = item['snippet']['channelTitle']\n",
    "            videos.append({\n",
    "                'video_id': video_id,\n",
    "                'title': title,\n",
    "                'description': description,\n",
    "                'published_at': published_at,\n",
    "                'thumbnail': thumbnail,\n",
    "                'channel': channel_title,\n",
    "                'url': f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "            })\n",
    "        return videos\n",
    "\n",
    "    def recommend_videos(self, query, channels, videos_per_channel=5):\n",
    "        all_videos = []\n",
    "        for channel in channels:\n",
    "            if channel.startswith('UC') and len(channel) == 24:\n",
    "                channel_id = channel\n",
    "            else:\n",
    "                channel_id = self.get_channel_id(channel)\n",
    "                if not channel_id:\n",
    "                    print(f\"Could not find channel: {channel}\")\n",
    "                    continue\n",
    "            videos = self.search_videos_in_channel(channel_id, query, videos_per_channel)\n",
    "            all_videos.extend(videos)\n",
    "        return all_videos\n",
    "\n",
    "def youtube_recommend(state: State, config: RunnableConfig):\n",
    "    api_key = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"YOUTUBE_API_KEY is not set\")\n",
    "    recommender = YouTubeVideoRecommender(api_key)\n",
    "    # List of favorite channels (names or IDs)\n",
    "    favorite_channels = [\n",
    "        \"ZEE Business\",\n",
    "        \"Economic Times\",\n",
    "        \"Times Now\",\n",
    "        \"Times Now Business\",\n",
    "        \"Times Now News\",\n",
    "        \"Times Now Politics\",\n",
    "        \"Times Now Sports\",\n",
    "        \"Times Now Science\",\n",
    "        \"Times Now Technology\",\n",
    "        \"Pranjal Kamra\",\n",
    "        \"Yadnya Investment Academy\",\n",
    "        \"CA Rachana Phadke Ranade\",\n",
    "        \"Invest Aaj For Kal\",\n",
    "        \"Market Gurukul\",\n",
    "        \"Warikoo\",\n",
    "        \"Asset Yogi\",\n",
    "        \"Trading Chanakya\",\n",
    "        \"Trade Brains\",\n",
    "        \"B Wealthy\",\n",
    "        \"Capital Pritika\",\n",
    "        \"The Urban Fight\",\n",
    "        \"Kritika Yadav\",\n",
    "        \"Gurleen Kaur Tikku\"\n",
    "    ]\n",
    "    query = state[\"research_topic\"]\n",
    "    recommendations = recommender.recommend_videos(query, favorite_channels, videos_per_channel=1)\n",
    "    if not recommendations:\n",
    "        summary = f\"No matching videos found for query: {query}\"\n",
    "    else:\n",
    "        summary = f\"## YouTube Video Recommendations for '{query}'\\n\\n\"\n",
    "        for i, video in enumerate(recommendations, 1):\n",
    "            summary += f\"### {i}. {video['title']}\\n\"\n",
    "            summary += f\"- Channel: {video['channel']}\\n\"\n",
    "            summary += f\"- URL: {video['url']}\\n\"\n",
    "            summary += f\"- Published: {video['published_at']}\\n\\n\"\n",
    "    return {\"running_summary\": summary, \"messages\": [HumanMessage(content=summary)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_evaluate(input_text):\n",
    "    parts = input_text.split(\"|||\")\n",
    "    query = parts[0]\n",
    "    response = parts[1]\n",
    "    sources = parts[2] if len(parts) > 2 else \"\"\n",
    "    \n",
    "    evaluation_prompt = f\"\"\"\n",
    "    Evaluate the following response to the query:\n",
    "    \n",
    "    QUERY: {query}\n",
    "    RESPONSE: {response}\n",
    "    SOURCES: {sources}\n",
    "    \n",
    "    Assess based on:\n",
    "    1. Factual accuracy (Does it match the sources?)\n",
    "    2. Completeness (Does it address all aspects of the query?)\n",
    "    3. Relevance (Is the information relevant to the query?)\n",
    "    4. Hallucination (Does it contain information not supported by sources?)\n",
    "    \n",
    "    Return a confidence score from 0-10 and a brief explanation.\n",
    "    \"\"\"\n",
    "    \n",
    "    evaluation = llm.predict(evaluation_prompt)\n",
    "    return evaluation\n",
    "\n",
    "def evaluate_response(state: State, config: RunnableConfig):\n",
    "    query = state.get(\"research_topic\", \"\")\n",
    "    response = state.get(\"running_summary\", \"\")\n",
    "    sources = \"\\n\".join(state.get(\"sources_gathered\", [])) or \"No sources available\"\n",
    "    input_text = f\"{query}|||{response}|||{sources}\"\n",
    "    evaluation = self_evaluate(input_text)\n",
    "    final_summary = response# + \"\\n\\n## Self Evaluation\\n\\n\" + evaluation\n",
    "    return {\"running_summary\": final_summary, \"messages\": [HumanMessage(content=final_summary)]}\n",
    "\n",
    "def evaluation_decision(state: State, config: RunnableConfig):\n",
    "    final_text = state.get(\"running_summary\", \"\")\n",
    "    prompt = f\"\"\"\n",
    "    The final output and self-evaluation are as follows:\n",
    "    {final_text}\n",
    "    \n",
    "    Based on the above, do you think additional insights should be added?\n",
    "    If yes, return a JSON object with the key \"next_route\" set to one of the following options:\n",
    "      - \"call_llm\" for additional financial analysis,\n",
    "      - \"web_research\" for further web research,\n",
    "      - \"answer_normal_query\" for more normal query insights,\n",
    "      #- \"parallel_branches\" to combine branches again.\n",
    "    If no additional insights are needed, return \"done\".\n",
    "    \n",
    "    For example:\n",
    "    {{\"next_route\": \"call_llm\"}}\n",
    "    \"\"\"\n",
    "    result = llm.invoke(prompt)\n",
    "    output_text = result.content.strip()\n",
    "    try:\n",
    "        decision = json.loads(output_text)\n",
    "        next_route = decision.get(\"next_route\", \"done\")\n",
    "    except Exception as e:\n",
    "        #print(\"Error in evaluation_decision:\", e)\n",
    "        next_route = \"done\"\n",
    "    # Optionally update state with next_route\n",
    "    state[\"next_route\"] = next_route\n",
    "    return {\"next_route\": next_route}\n",
    "\n",
    "def get_route(state: State) -> str:\n",
    "    return state[\"route\"]\n",
    "\n",
    "def call_route_first_step(state: State):\n",
    "    image_processed = state.get(\"image_processed\", False)\n",
    "    if state.get(\"image\") and len(state[\"image\"]) > 0 and not image_processed:\n",
    "        return {\"route\": \"Image_Analysis\", \"original_messages\": state[\"original_messages\"]}\n",
    "    \n",
    "    router_response = llm.with_structured_output(Route_First_Step).invoke(state[\"research_topic\"])\n",
    "    print(f\"Routing result: {router_response.step}\")\n",
    "    return {\"route\": router_response.step, \"original_messages\": state[\"original_messages\"]}\n",
    "\n",
    "def validate_state_transition(old_state: State, new_state: State):\n",
    "    required_fields = set(State.__annotations__.keys())\n",
    "    missing = required_fields - set(new_state.keys())\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing state updates for: {missing}\")\n",
    "    return True\n",
    "\n",
    "def after_image_analysis(state):\n",
    "    return {**state}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gemma3(state: State):\n",
    "    try:\n",
    "        image_path = state[\"image\"][0]\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            image_b64 = base64.b64encode(f.read()).decode()\n",
    "\n",
    "        assert len(image_b64) < 180_000, \\\n",
    "            \"To upload larger images, use the assets API (see docs)\"\n",
    "        \n",
    "        try:\n",
    "            invoke_url = \"https://integrate.api.nvidia.com/v1/chat/completions\"\n",
    "            headers = {\n",
    "                \"Authorization\": \"Bearer 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\",\n",
    "                \"Accept\": \"application/json\"\n",
    "            }\n",
    "            \n",
    "            payload = {\n",
    "                \"model\": \"google/gemma-3-27b-it\",\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"Describe what you see in this image. Focus on any charts, financial data, or technical analysis elements if present.\\n<img src=\\\"data:image/png;base64,{image_b64}\\\" />\"\n",
    "                    }\n",
    "                ],\n",
    "                \"max_tokens\": 512,\n",
    "                \"temperature\": 0.20,\n",
    "                \"top_p\": 0.70,\n",
    "                \"stream\": False\n",
    "            }\n",
    "            \n",
    "            gemma_response = requests.post(invoke_url, headers=headers, json=payload)\n",
    "            gemma_response.raise_for_status()\n",
    "            data = gemma_response.json()\n",
    "            full_response = data[\"choices\"][0][\"message\"][\"content\"] if \"choices\" in data and data[\"choices\"] else \"\"\n",
    "        except Exception as e:\n",
    "            fallback_prompt = f\"Describe what you see in this image. The image appears to be a financial chart or technical analysis pattern graph from Investopedia. Please describe the patterns, trends, and elements visible in the chart.\"\n",
    "            full_response = llm.invoke(fallback_prompt).content\n",
    "        \n",
    "        markdown_response = f\"## Image Analysis Results\\n\\n{full_response}\"\n",
    "        updated_messages = state[\"messages\"] + [HumanMessage(content=markdown_response)]\n",
    "        \n",
    "        route_prompt = \"Based on the image analysis of what appears to be a financial chart or technical analysis pattern, what should be the next step? Choose one: Web_query, Normal_query, Financial_Analysis, YouTube_Recommender\"\n",
    "        next_route = llm.invoke(route_prompt).content.strip()\n",
    "        for route in [\"Web_query\", \"Normal_query\", \"Financial_Analysis\", \"YouTube_Recommender\"]:\n",
    "            if route in next_route:\n",
    "                next_route = route\n",
    "                break\n",
    "        else:\n",
    "            next_route = \"Normal_query\"\n",
    "        \n",
    "        return {\n",
    "            \"running_summary\": markdown_response,\n",
    "            \"messages\": updated_messages,\n",
    "            \"image_processed\": True,\n",
    "            \"route\": next_route,\n",
    "            \"research_topic\": state[\"research_topic\"],\n",
    "            \"search_query\": state.get(\"search_query\", \"\"),\n",
    "            \"web_research_results\": state.get(\"web_research_results\", []),\n",
    "            \"sources_gathered\": state.get(\"sources_gathered\", []),\n",
    "            \"research_loop_count\": state.get(\"research_loop_count\", 0),\n",
    "            \"image\": state[\"image\"],\n",
    "            \"original_messages\": state[\"original_messages\"]  # Preserve original messages\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"running_summary\": str(e),\n",
    "            \"messages\": state[\"messages\"] + [HumanMessage(content=str(e))],\n",
    "            \"image_processed\": True,\n",
    "            \"route\": \"Normal_query\",\n",
    "            \"research_topic\": state[\"research_topic\"],\n",
    "            \"search_query\": state.get(\"search_query\", \"\"),\n",
    "            \"web_research_results\": state.get(\"web_research_results\", []),\n",
    "            \"sources_gathered\": state.get(\"sources_gathered\", []),\n",
    "            \"research_loop_count\": state.get(\"research_loop_count\", 0),\n",
    "            \"image\": state[\"image\"],\n",
    "            \"original_messages\": state[\"original_messages\"]  # Preserve original messages\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_with_context(state: State):\n",
    "    \"\"\"Node for processing queries with conversation context\"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "    original_messages = state.get(\"original_messages\", [])\n",
    "    \n",
    "    if len(messages) <= 1:  # Only the current message, no context\n",
    "        return state\n",
    "    \n",
    "    # Last message is the current query\n",
    "    current_query = messages[-1].content\n",
    "    \n",
    "    # Add the current query to original_messages if it's not already there\n",
    "    if not original_messages or original_messages[-1].content != current_query:\n",
    "        original_messages.append(HumanMessage(content=current_query))\n",
    "    \n",
    "    context_messages = messages[:-1]\n",
    "    \n",
    "    # Format the context for the prompt\n",
    "    context_str = \"\\n\".join([f\"{'User' if i % 2 == 0 else 'Assistant'}: {msg.content}\" \n",
    "                             for i, msg in enumerate(context_messages[-6:])])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Based on the previous conversation context and the user's current query, generate an enhanced version of the query that incorporates relevant context. However, if the query is about plotting a graph, preserve its intent and format it into one of these exact structures with the company ticker as the last word:\n",
    "    - \"Show me a candlestick chart for TICKER\"\n",
    "    - \"Show me the balance sheet for TICKER\"\n",
    "    - \"Show me the assets for TICKER\"\n",
    "    \n",
    "    Previous conversation:\n",
    "    {context_str}\n",
    "    \n",
    "    Current query: {current_query}\n",
    "    \n",
    "    Instructions:\n",
    "    1. If the query mentions 'candlestick', 'balance sheet', or 'assets' (or similar terms like 'chart', 'visualize'), identify the ticker (e.g., AAPL, MSFT) and rephrase it into one of the above formats.\n",
    "    2. For non-plot queries, enhance the query with context as needed.\n",
    "    3. Ensure the ticker, if present, is always the last word in plot-related queries.\n",
    "    \n",
    "    Enhanced query:\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        enhanced_query = llm.invoke(prompt).content.strip()\n",
    "        # Update the last message with the enhanced query in messages\n",
    "        updated_messages = messages[:-1] + [HumanMessage(content=enhanced_query)]\n",
    "        return {\n",
    "            \"messages\": updated_messages,\n",
    "            \"original_messages\": original_messages,\n",
    "            \"research_topic\": enhanced_query\n",
    "        }\n",
    "    except Exception as e:\n",
    "        # On error, return state with original messages preserved\n",
    "        return {\n",
    "            \"messages\": messages,\n",
    "            \"original_messages\": original_messages,\n",
    "            \"research_topic\": state[\"research_topic\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_router():\n",
    "    final_router = StateGraph(State)\n",
    "    \n",
    "    # Add all nodes\n",
    "    final_router.add_node(\"route_first_step\", call_route_first_step)\n",
    "    final_router.add_node(\"generate_query\", generate_query)\n",
    "    final_router.add_node(\"web_research\", web_research)\n",
    "    final_router.add_node(\"summarize_sources\", summarize_sources)\n",
    "    final_router.add_node(\"reflect_on_summary\", reflect_on_summary)\n",
    "    final_router.add_node(\"finalize_summary\", finalize_summary)\n",
    "    final_router.add_node('call_llm', call_llm)\n",
    "    final_router.add_node('take_action', take_action)\n",
    "    final_router.add_node('format_financial_analysis', format_financial_analysis)\n",
    "    final_router.add_node('answer_normal_query', answer_normal_query)\n",
    "    final_router.add_node('youtube_recommend', youtube_recommend)\n",
    "    final_router.add_node(\"self_evaluate_final\", evaluate_response)\n",
    "    final_router.add_node(\"evaluation_decision\", evaluation_decision)\n",
    "    final_router.add_node(\"process_with_context\", process_with_context)\n",
    "    # Add the new image processing node\n",
    "    final_router.add_node(\"image_analysis\", call_gemma3)\n",
    "\n",
    "    final_router.add_node(\"parse_query\", parse_query)\n",
    "    final_router.add_node(\"generate_plot\", generate_plot)\n",
    "    final_router.add_node(\"format_response\", format_response)\n",
    "    \n",
    "    # Define connections\n",
    "    final_router.add_edge(START, \"process_with_context\")\n",
    "    final_router.add_edge(\"process_with_context\", \"route_first_step\")\n",
    "    \n",
    "    # Update conditional edges to include Image_Analysis route\n",
    "    final_router.add_conditional_edges(\"route_first_step\", get_route, {\n",
    "        'Image_Analysis': 'image_analysis',\n",
    "        'Web_query': 'generate_query',\n",
    "        'Normal_query': 'answer_normal_query',\n",
    "        'Financial_Analysis': 'call_llm',\n",
    "        'YouTube_Recommender': 'youtube_recommend',\n",
    "        'Plot_Graph': 'parse_query'\n",
    "    })\n",
    "    \n",
    "    # Add edge from image_analysis to subsequent routing\n",
    "    final_router.add_edge(\"parse_query\", \"generate_plot\")\n",
    "    final_router.add_edge(\"generate_plot\", \"format_response\")\n",
    "    final_router.add_edge(\"image_analysis\", \"route_first_step\")\n",
    "    \n",
    "    final_router.add_edge(\"answer_normal_query\", 'self_evaluate_final')\n",
    "    final_router.add_edge(\"format_response\", 'self_evaluate_final')\n",
    "    \n",
    "    final_router.add_conditional_edges(\n",
    "        \"call_llm\",\n",
    "        exists_action,\n",
    "        {True: \"take_action\", False: \"format_financial_analysis\"}\n",
    "    )\n",
    "    final_router.add_edge(\"take_action\", \"format_financial_analysis\")\n",
    "    final_router.add_edge(\"format_financial_analysis\", END)\n",
    "    \n",
    "    final_router.add_edge(\"generate_query\", \"web_research\")\n",
    "    final_router.add_edge(\"web_research\", \"summarize_sources\")\n",
    "    final_router.add_edge(\"summarize_sources\", \"reflect_on_summary\")\n",
    "    final_router.add_conditional_edges(\"reflect_on_summary\", route_research)\n",
    "    final_router.add_edge(\"finalize_summary\", 'self_evaluate_final')\n",
    "    final_router.add_edge(\"self_evaluate_final\", 'evaluation_decision')\n",
    "    \n",
    "    final_router.add_conditional_edges(\"evaluation_decision\", lambda x: x.get(\"next_route\", \"done\"), {\n",
    "        'done': END,\n",
    "        'call_llm': 'call_llm',\n",
    "        'web_research': 'web_research',\n",
    "        'answer_normal_query': 'answer_normal_query',\n",
    "        'YouTube_Recommender': 'youtube_recommend'\n",
    "    })\n",
    "    final_router.add_edge(\"youtube_recommend\", END)\n",
    "    \n",
    "    return final_router.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query: Show me a candlestick chart for AAPL\n",
    "#Query: Show me the balance sheet for MSFT\n",
    "#Query: Show me the assets for GOOGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
