{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n",
    "import json\n",
    "import getpass\n",
    "import operator\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass, fields\n",
    "from typing import Any, Dict, List, Optional\n",
    "from typing_extensions import TypedDict, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "from langsmith import traceable\n",
    "# IPython for display (if needed)\n",
    "from IPython.display import Image, display, Markdown\n",
    "\n",
    "# Import LangChain and related tools\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableParallel, RunnableLambda, RunnableBranch\n",
    "from langchain_core.tools import tool, StructuredTool\n",
    "from langchain_core import tools  # if needed\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# For financial data via yfinance\n",
    "import yfinance as yf\n",
    "\n",
    "# For web search and HTML parsing\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# For environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# For YouTube video recommendations\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "\n",
    "# For state graph\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from tavily import TavilyClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model_name='Gemma2-9b-it', api_key=os.getenv('GROQ_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_writer_instruction_web = \"\"\"Your goal is to generate a targeted web search query related to financial investments or any finance-related topic specified by the user.\n",
    "\n",
    "<TOPIC>\n",
    "{finance_topic}\n",
    "</TOPIC>\n",
    "\n",
    "<FORMAT>\n",
    "Format your response as a JSON object with ALL three of these exact keys:\n",
    "   - \"query\": The actual search query string\n",
    "   - \"aspect\": The specific aspect of the finance topic being researched\n",
    "   - \"rationale\": Brief explanation of why this query is relevant\n",
    "</FORMAT>\n",
    "\n",
    "<EXAMPLE>\n",
    "Example output:\n",
    "{{\n",
    "    \"query\": \"best index funds for long-term investment 2025\",\n",
    "    \"aspect\": \"investment strategy\",\n",
    "    \"rationale\": \"Identifying top-performing index funds for long-term portfolio growth\"\n",
    "}}\n",
    "</EXAMPLE>\n",
    "\n",
    "Provide your response in JSON format:\n",
    "\"\"\"\n",
    "\n",
    "summarizer_instruction_web = \"\"\"<GOAL>\n",
    "Generate a high-quality summary of the web search results, focusing on financial investments or the specific finance-related topic requested by the user.\n",
    "</GOAL>\n",
    "\n",
    "<REQUIREMENTS>\n",
    "When creating a NEW summary:\n",
    "1. Highlight the most relevant financial insights, trends, or strategies from the search results.\n",
    "2. Ensure a coherent flow of information while keeping it concise and actionable.\n",
    "\n",
    "When EXTENDING an existing summary:\n",
    "1. Read the existing summary and new search results carefully.\n",
    "2. Compare the new information with the existing summary.\n",
    "3. For each piece of new information:\n",
    "    a. If it builds on an existing point, integrate it smoothly.\n",
    "    b. If it introduces a new relevant aspect, add a separate paragraph.\n",
    "    c. If it’s irrelevant to financial investments, ignore it.\n",
    "4. Ensure all additions align with the user’s finance-related query.\n",
    "5. Verify that the final output differs from the original summary while improving its depth.\n",
    "\n",
    "<FORMATTING>\n",
    "- Start directly with the updated summary, without preamble or titles. Do not use XML tags in the output.\n",
    "</FORMATTING>\n",
    "\"\"\"\n",
    "\n",
    "reflection_instructions_web = \"\"\"You are an expert financial research assistant analyzing a summary about {finance_topic}.\n",
    "\n",
    "<GOAL>\n",
    "1. Identify missing details or areas that need deeper exploration.\n",
    "2. Generate a follow-up question to help expand financial knowledge.\n",
    "3. Focus on investment strategies, market trends, risk factors, regulations, or financial instruments that weren’t fully covered.\n",
    "</GOAL>\n",
    "\n",
    "<REQUIREMENTS>\n",
    "Ensure the follow-up question is self-contained and provides necessary context for a web search.\n",
    "</REQUIREMENTS>\n",
    "\n",
    "<FORMAT>\n",
    "Format your response as a JSON object with these exact keys:\n",
    "- \"knowledge_gap\": Describe what financial information is missing or unclear.\n",
    "- \"follow_up_query\": Write a specific question to address this gap.\n",
    "</FORMAT>\n",
    "\n",
    "<EXAMPLE>\n",
    "Example output:\n",
    "{{\n",
    "    \"knowledge_gap\": \"The summary does not mention tax implications of investing in ETFs vs. mutual funds.\",\n",
    "    \"follow_up_query\": \"What are the tax advantages and disadvantages of ETFs compared to mutual funds?\"\n",
    "}}\n",
    "</EXAMPLE>\n",
    "\n",
    "Provide your analysis in JSON format:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    route: Literal['Web_query', 'Normal_query', 'Financial_Analysis', 'YouTube_Recommender'] = Field(None)\n",
    "    research_topic: str\n",
    "    search_query: str\n",
    "    web_research_results: List[str]\n",
    "    sources_gathered: List[str]\n",
    "    research_loop_count: int\n",
    "    running_summary: str\n",
    "    image: list[str]\n",
    "    image_processed: bool\n",
    "    messages: List[Any]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initial_state(user_query: str, image: list[str] = []) -> State:\n",
    "    return {\n",
    "        \"route\": None,\n",
    "        \"research_topic\": user_query,\n",
    "        \"search_query\": \"\",\n",
    "        \"web_research_results\": [],\n",
    "        \"sources_gathered\": [],\n",
    "        \"research_loop_count\": 0,\n",
    "        \"running_summary\": \"\",\n",
    "        \"image\": image,\n",
    "        \"image_processed\": False,\n",
    "        \"messages\": [HumanMessage(content=user_query)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Route_First_Step(BaseModel):\n",
    "    # Updated to include YouTube_Recommender\n",
    "    step: Literal['Web_query', 'Normal_query', 'Financial_Analysis', 'YouTube_Recommender'] = Field(\n",
    "        None,\n",
    "        description='Determine whether to perform a web search, answer a normal question, perform a financial analysis, or recommend YouTube videos.'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchAPI(Enum):\n",
    "    PERPLEXITY = \"perplexity\"\n",
    "    TAVILY = \"tavily\"\n",
    "    DUCKDUCKGO = \"duckduckgo\"\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class Configuration:\n",
    "    max_web_research_loops: int = int(os.environ.get(\"MAX_WEB_RESEARCH_LOOPS\", \"3\"))\n",
    "    search_api: SearchAPI = SearchAPI(os.environ.get(\"SEARCH_API\", \"tavily\"))\n",
    "    fetch_full_page: bool = os.environ.get(\"FETCH_FULL_PAGE\", \"False\").lower() in (\"true\", \"1\", \"t\")\n",
    "    ollama_base_url: str = os.environ.get(\"OLLAMA_BASE_URL\", \"http://localhost:11434/\")\n",
    "\n",
    "    @classmethod\n",
    "    def from_runnable_config(cls, config: Optional[RunnableConfig] = None) -> \"Configuration\":\n",
    "        configurable = config[\"configurable\"] if config and \"configurable\" in config else {}\n",
    "        values: dict[str, Any] = {\n",
    "            f.name: os.environ.get(f.name.upper(), configurable.get(f.name))\n",
    "            for f in fields(cls)\n",
    "            if f.init\n",
    "        }\n",
    "        return cls(**{k: v for k, v in values.items() if v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "def tavily_search(query, include_raw_content=True, max_results=3):\n",
    "    api_key = os.environ['TAVILY_API_KEY']\n",
    "    if not api_key:\n",
    "        raise ValueError(\"TAVILY_API_KEY environment variable is not set\")\n",
    "    tavily_client = TavilyClient(api_key=api_key)\n",
    "    return tavily_client.search(query, max_results=max_results, include_raw_content=include_raw_content)\n",
    "\n",
    "def deduplicate_and_format_sources(search_response, max_tokens_per_source, include_raw_content=False):\n",
    "    if isinstance(search_response, dict):\n",
    "        sources_list = search_response['results']\n",
    "    elif isinstance(search_response, list):\n",
    "        sources_list = []\n",
    "        for response in search_response:\n",
    "            if isinstance(response, dict) and 'results' in response:\n",
    "                sources_list.extend(response['results'])\n",
    "            else:\n",
    "                sources_list.extend(response)\n",
    "    else:\n",
    "        raise ValueError(\"Input must be either a dict with 'results' or a list of search results\")\n",
    "\n",
    "    unique_sources = {}\n",
    "    for source in sources_list:\n",
    "        if source['url'] not in unique_sources:\n",
    "            unique_sources[source['url']] = source\n",
    "\n",
    "    formatted_text = \"Sources:\\n\\n\"\n",
    "    for source in unique_sources.values():\n",
    "        formatted_text += f\"Source {source['title']}:\\n===\\n\"\n",
    "        formatted_text += f\"URL: {source['url']}\\n===\\n\"\n",
    "        formatted_text += f\"Most relevant content from source: {source['content']}\\n===\\n\"\n",
    "        if include_raw_content:\n",
    "            char_limit = max_tokens_per_source * 4\n",
    "            raw_content = source.get('raw_content', '') or ''\n",
    "            if len(raw_content) > char_limit:\n",
    "                raw_content = raw_content[:char_limit] + \"... [truncated]\"\n",
    "            formatted_text += f\"Full source content limited to {max_tokens_per_source} tokens: {raw_content}\\n\\n\"\n",
    "\n",
    "    return formatted_text.strip()\n",
    "\n",
    "def format_sources(search_results):\n",
    "    return '\\n'.join(\n",
    "        f\"* {source['title']} : {source['url']}\"\n",
    "        for source in search_results['results']\n",
    "    )\n",
    "\n",
    "def generate_query(state: State, config: RunnableConfig):\n",
    "    prompt = query_writer_instruction_web.format(finance_topic=state[\"research_topic\"]) + \"\\nGenerate a query for web search:\"\n",
    "    result = llm.invoke(prompt)\n",
    "    output_text = result.content.strip()\n",
    "    try:\n",
    "        query_data = json.loads(output_text)\n",
    "        return {\"search_query\": query_data['query']}\n",
    "    except (json.JSONDecodeError, KeyError) as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        return {\"search_query\": f\"comprehensive analysis of {state['research_topic']}\"}\n",
    "\n",
    "def web_research(state: State, config: RunnableConfig):\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    search_api = configurable.search_api.value if isinstance(configurable.search_api, Enum) is False else configurable.search_api.value\n",
    "    if search_api == \"tavily\":\n",
    "        search_results = tavily_search(state[\"search_query\"], include_raw_content=True, max_results=1)\n",
    "        search_str = deduplicate_and_format_sources(search_results, max_tokens_per_source=1000, include_raw_content=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported search API: {configurable.search_api}\")\n",
    "    return {\n",
    "        \"sources_gathered\": [format_sources(search_results)],\n",
    "        \"research_loop_count\": state[\"research_loop_count\"] + 1,\n",
    "        \"web_research_results\": [search_str]\n",
    "    }\n",
    "\n",
    "def summarize_sources(state: State, config: RunnableConfig):\n",
    "    existing_summary = state['running_summary']\n",
    "    most_recent_web_research = state['web_research_results'][-1]\n",
    "    if existing_summary:\n",
    "        human_message_content = (\n",
    "            f\"<User Input> \\n {state['research_topic']} \\n <User Input>\\n\\n\"\n",
    "            f\"<Existing Summary> \\n {existing_summary} \\n <Existing Summary>\\n\\n\"\n",
    "            f\"<New Search Results> \\n {most_recent_web_research} \\n <New Search Results>\"\n",
    "        )\n",
    "    else:\n",
    "        human_message_content = (\n",
    "            f\"<User Input> \\n {state['research_topic']} \\n <User Input>\\n\\n\"\n",
    "            f\"<Search Results> \\n {most_recent_web_research} \\n <Search Results>\"\n",
    "        )\n",
    "    prompt = summarizer_instruction_web + \"\\n\" + human_message_content\n",
    "    result = llm.invoke(prompt)\n",
    "    running_summary = result.content\n",
    "    while \"<think>\" in running_summary and \"</think>\" in running_summary:\n",
    "        start = running_summary.find(\"<think>\")\n",
    "        end = running_summary.find(\"</think>\") + len(\"</think>\")\n",
    "        running_summary = running_summary[:start] + running_summary[end:]\n",
    "    return {\"running_summary\": running_summary}\n",
    "\n",
    "def reflect_on_summary(state: State, config: RunnableConfig):\n",
    "    prompt = reflection_instructions_web.format(finance_topic=state['research_topic']) \\\n",
    "             + \"\\nIdentify a knowledge gap and generate a follow-up web search query based on our existing knowledge: \" \\\n",
    "             + state['running_summary']\n",
    "    result = llm.invoke(prompt)\n",
    "    output_text = result.content.strip()\n",
    "    try:\n",
    "        follow_up_query = json.loads(output_text)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: Could not decode JSON from reflect_on_summary. Response was:\", output_text)\n",
    "        follow_up_query = {\"follow_up_query\": f\"Tell me more about {state['research_topic']}\"}\n",
    "    query = follow_up_query.get('follow_up_query')\n",
    "    if not query:\n",
    "        return {\"search_query\": f\"Tell me more about {state['research_topic']}\"}\n",
    "    return {\"search_query\": query}\n",
    "\n",
    "def finalize_summary(state: State):\n",
    "    all_sources = \"\\n\".join(source for source in state['sources_gathered'])\n",
    "    final_summary = f\"## Web Research Summary\\n\\n{state['running_summary']}\\n\\n### Sources:\\n{all_sources}\"\n",
    "    final_message = HumanMessage(content=final_summary)\n",
    "    return {\"running_summary\": final_summary, \"messages\": [final_message]}\n",
    "\n",
    "def route_research(state: State, config: RunnableConfig) -> Literal[\"finalize_summary\", \"web_research\"]:\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    if state['research_loop_count'] < configurable.max_web_research_loops:\n",
    "        return \"web_research\"\n",
    "    return \"finalize_summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def company_address(ticker: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns company address for input ticker.\n",
    "    e.g. company_address: AAPL\n",
    "    Returns company address for ticker AAPL which is stock ticker for Apple Inc.\n",
    "    \"\"\"\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    info = ticker_obj.get_info()\n",
    "\n",
    "    return \" \".join([info[key] for key in ['address1','city','state','zip','country']])\n",
    "\n",
    "@tool\n",
    "def fulltime_employees(ticker: str) -> int:\n",
    "    \"\"\"\n",
    "    Returns fulltime employees count for input ticker.\n",
    "    e.g. company_address: MSFT\n",
    "    Returns fulltime employees count for ticker MSFT which is stock ticker for Microsoft.\n",
    "    \"\"\"\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    info = ticker_obj.get_info()\n",
    "\n",
    "    return info['fullTimeEmployees']\n",
    "\n",
    "@tool\n",
    "def last_close_price(ticker: str) -> float:\n",
    "    \"\"\"\n",
    "    Returns last close price for input ticker.\n",
    "    e.g. company_address: MSFT\n",
    "    Returns last close price for ticker MSFT which is stock ticker for Microsoft.\n",
    "    \"\"\"\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    info = ticker_obj.get_info()\n",
    "\n",
    "    return info['previousClose']\n",
    "\n",
    "@tool\n",
    "def EBITDA(ticker: str) -> float:\n",
    "    \"\"\"\n",
    "    Returns EBITDA for input ticker.\n",
    "    e.g. company_address: AAPL\n",
    "    Returns EBITDA for ticker AAPL which is stock ticker for Apple Inc.\n",
    "    \"\"\"\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    info = ticker_obj.get_info()\n",
    "\n",
    "    return info['ebitda']\n",
    "\n",
    "@tool\n",
    "def total_debt(ticker: str) -> float:\n",
    "    \"\"\"\n",
    "    Returns total debt for input ticker.\n",
    "    e.g. company_address: AAPL\n",
    "    Returns total debt for ticker AAPL which is stock ticker for Apple Inc.\n",
    "    \"\"\"\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    info = ticker_obj.get_info()\n",
    "\n",
    "    return info['totalDebt']\n",
    "\n",
    "@tool\n",
    "def total_revenue(ticker: str) -> float:\n",
    "    \"\"\"\n",
    "    Returns total revenue for input ticker.\n",
    "    e.g. company_address: MSFT\n",
    "    Returns total revenue for ticker MSFT which is stock ticker for Microsoft.\n",
    "    \"\"\"\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    info = ticker_obj.get_info()\n",
    "\n",
    "    return info['totalRevenue']\n",
    "\n",
    "@tool\n",
    "def debt_to_equity_ratio(ticker: str) -> float:\n",
    "    \"\"\"\n",
    "    Returns debt to equity ratio for input ticker.\n",
    "    e.g. company_address: AAPL\n",
    "    Returns debt to equity ratio for ticker AAPL which is stock ticker for Apple Inc.\n",
    "    \"\"\"\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    info = ticker_obj.get_info()\n",
    "\n",
    "    return info['debtToEquity']\n",
    "\n",
    "finance_tools = [\n",
    "    company_address,\n",
    "    fulltime_employees,\n",
    "    last_close_price,\n",
    "    EBITDA,\n",
    "    total_debt,\n",
    "    total_revenue,\n",
    "    debt_to_equity_ratio\n",
    "]\n",
    "finance_tool_map = {t.name: t for t in finance_tools}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_normal = llm\n",
    "normal_query_prompt = \"\"\"\n",
    "You are a financial analyst. Please answer the user's question based on what you know, don't make up anything.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_normal_query(state: State):\n",
    "    messages = state.get('messages', [])\n",
    "    system_message = SystemMessage(content=normal_query_prompt + \"\\nFormat your response in Markdown.\")\n",
    "    response = llm_normal.invoke([system_message] + messages)\n",
    "    markdown_response = f\"## Normal Query Response\\n\\n{response.content}\"\n",
    "    return {\"running_summary\": markdown_response, \"messages\": [HumanMessage(content=markdown_response)]}\n",
    "\n",
    "llm_financial_analysis = llm.bind_tools(finance_tools, tool_choice='auto')\n",
    "financial_analysis_prompt = \"\"\"\n",
    "You are a financial analyst. You are given tools for accurate data.\n",
    "\"\"\"\n",
    "\n",
    "def call_llm(state: State):\n",
    "    messages = state['messages']\n",
    "    system_prompt = financial_analysis_prompt + \"\\nFormat your response in Markdown.\"\n",
    "    messages = [SystemMessage(content=system_prompt)] + messages\n",
    "    message = llm_financial_analysis.invoke(messages)\n",
    "    return {'messages': [message]}\n",
    "\n",
    "def exists_action(state: State):\n",
    "    result = state['messages'][-1]\n",
    "    return len(result.tool_calls) > 0\n",
    "\n",
    "def take_action(state: State):\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    tool_results = []\n",
    "    for t in tool_calls:\n",
    "        try:\n",
    "            tool_func = finance_tool_map[t['name']]\n",
    "            result = tool_func.invoke(t['args'])\n",
    "        except KeyError:\n",
    "            result = f\"Error: Tool {t['name']} not found\"\n",
    "        except Exception as e:\n",
    "            result = f\"Error executing tool: {str(e)}\"\n",
    "        tool_results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "    markdown_output = \"## Financial Analysis Results\\n\\n\"\n",
    "    for result in tool_results:\n",
    "        markdown_output += f\"### {result.name.replace('_', ' ').title()}\\n\\n{result.content}\\n\\n\"\n",
    "    return {'messages': tool_results, 'running_summary': markdown_output}\n",
    "\n",
    "def format_financial_analysis(state: State):\n",
    "    messages = state['messages']\n",
    "    tool_results = [msg for msg in messages if isinstance(msg, ToolMessage)]\n",
    "    if tool_results:\n",
    "        markdown_output = \"## Financial Analysis Results\\n\\n\"\n",
    "        for result in tool_results:\n",
    "            markdown_output += f\"### {result.name.replace('_', ' ').title()}\\n\\n{result.content}\\n\\n\"\n",
    "    else:\n",
    "        markdown_output = f\"## Financial Analysis\\n\\n{messages[-1].content}\"\n",
    "    return {\"running_summary\": markdown_output, \"messages\": [HumanMessage(content=markdown_output)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YouTubeVideoRecommender:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "    \n",
    "    def get_channel_id(self, channel_name):\n",
    "        request = self.youtube.search().list(\n",
    "            part=\"snippet\",\n",
    "            q=channel_name,\n",
    "            type=\"channel\",\n",
    "            maxResults=1\n",
    "        )\n",
    "        response = request.execute()\n",
    "        if response['items']:\n",
    "            return response['items'][0]['id']['channelId']\n",
    "        return None\n",
    "    \n",
    "    def search_videos_in_channel(self, channel_id, query, max_results=10):\n",
    "        request = self.youtube.search().list(\n",
    "            part=\"snippet\",\n",
    "            channelId=channel_id,\n",
    "            q=query,\n",
    "            type=\"video\",\n",
    "            maxResults=max_results\n",
    "        )\n",
    "        response = request.execute()\n",
    "        videos = []\n",
    "        for item in response['items']:\n",
    "            video_id = item['id']['videoId']\n",
    "            title = item['snippet']['title']\n",
    "            description = item['snippet']['description']\n",
    "            published_at = item['snippet']['publishedAt']\n",
    "            thumbnail = item['snippet']['thumbnails']['high']['url']\n",
    "            channel_title = item['snippet']['channelTitle']\n",
    "            videos.append({\n",
    "                'video_id': video_id,\n",
    "                'title': title,\n",
    "                'description': description,\n",
    "                'published_at': published_at,\n",
    "                'thumbnail': thumbnail,\n",
    "                'channel': channel_title,\n",
    "                'url': f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "            })\n",
    "        return videos\n",
    "\n",
    "    def recommend_videos(self, query, channels, videos_per_channel=5):\n",
    "        all_videos = []\n",
    "        for channel in channels:\n",
    "            if channel.startswith('UC') and len(channel) == 24:\n",
    "                channel_id = channel\n",
    "            else:\n",
    "                channel_id = self.get_channel_id(channel)\n",
    "                if not channel_id:\n",
    "                    print(f\"Could not find channel: {channel}\")\n",
    "                    continue\n",
    "            videos = self.search_videos_in_channel(channel_id, query, videos_per_channel)\n",
    "            all_videos.extend(videos)\n",
    "        return all_videos\n",
    "\n",
    "def youtube_recommend(state: State, config: RunnableConfig):\n",
    "    api_key = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"YOUTUBE_API_KEY is not set\")\n",
    "    recommender = YouTubeVideoRecommender(api_key)\n",
    "    # List of favorite channels (names or IDs)\n",
    "    favorite_channels = [\n",
    "        \"ZEE Business\",\n",
    "        \"Economic Times\",\n",
    "        \"Times Now\",\n",
    "        \"Times Now Business\",\n",
    "        \"Times Now News\",\n",
    "        \"Times Now Politics\",\n",
    "        \"Times Now Sports\",\n",
    "        \"Times Now Science\",\n",
    "        \"Times Now Technology\",\n",
    "        \"Pranjal Kamra\",\n",
    "        \"Yadnya Investment Academy\",\n",
    "        \"CA Rachana Phadke Ranade\",\n",
    "        \"Invest Aaj For Kal\",\n",
    "        \"Market Gurukul\",\n",
    "        \"Warikoo\",\n",
    "        \"Asset Yogi\",\n",
    "        \"Trading Chanakya\",\n",
    "        \"Trade Brains\",\n",
    "        \"B Wealthy\",\n",
    "        \"Capital Pritika\",\n",
    "        \"The Urban Fight\",\n",
    "        \"Kritika Yadav\",\n",
    "        \"Gurleen Kaur Tikku\"\n",
    "    ]\n",
    "    query = state[\"research_topic\"]\n",
    "    recommendations = recommender.recommend_videos(query, favorite_channels, videos_per_channel=1)\n",
    "    if not recommendations:\n",
    "        summary = f\"No matching videos found for query: {query}\"\n",
    "    else:\n",
    "        summary = f\"## YouTube Video Recommendations for '{query}'\\n\\n\"\n",
    "        for i, video in enumerate(recommendations, 1):\n",
    "            summary += f\"### {i}. {video['title']}\\n\"\n",
    "            summary += f\"- Channel: {video['channel']}\\n\"\n",
    "            summary += f\"- URL: {video['url']}\\n\"\n",
    "            summary += f\"- Published: {video['published_at']}\\n\\n\"\n",
    "    return {\"running_summary\": summary, \"messages\": [HumanMessage(content=summary)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_evaluate(input_text):\n",
    "    parts = input_text.split(\"|||\")\n",
    "    query = parts[0]\n",
    "    response = parts[1]\n",
    "    sources = parts[2] if len(parts) > 2 else \"\"\n",
    "    \n",
    "    evaluation_prompt = f\"\"\"\n",
    "    Evaluate the following response to the query:\n",
    "    \n",
    "    QUERY: {query}\n",
    "    RESPONSE: {response}\n",
    "    SOURCES: {sources}\n",
    "    \n",
    "    Assess based on:\n",
    "    1. Factual accuracy (Does it match the sources?)\n",
    "    2. Completeness (Does it address all aspects of the query?)\n",
    "    3. Relevance (Is the information relevant to the query?)\n",
    "    4. Hallucination (Does it contain information not supported by sources?)\n",
    "    \n",
    "    Return a confidence score from 0-10 and a brief explanation.\n",
    "    \"\"\"\n",
    "    \n",
    "    evaluation = llm.predict(evaluation_prompt)\n",
    "    return evaluation\n",
    "\n",
    "def evaluate_response(state: State, config: RunnableConfig):\n",
    "    query = state.get(\"research_topic\", \"\")\n",
    "    response = state.get(\"running_summary\", \"\")\n",
    "    sources = \"\\n\".join(state.get(\"sources_gathered\", [])) or \"No sources available\"\n",
    "    input_text = f\"{query}|||{response}|||{sources}\"\n",
    "    evaluation = self_evaluate(input_text)\n",
    "    final_summary = response + \"\\n\\n## Self Evaluation\\n\\n\" + evaluation\n",
    "    return {\"running_summary\": final_summary, \"messages\": [HumanMessage(content=final_summary)]}\n",
    "\n",
    "def evaluation_decision(state: State, config: RunnableConfig):\n",
    "    final_text = state.get(\"running_summary\", \"\")\n",
    "    prompt = f\"\"\"\n",
    "    The final output and self-evaluation are as follows:\n",
    "    {final_text}\n",
    "    \n",
    "    Based on the above, do you think additional insights should be added?\n",
    "    If yes, return a JSON object with the key \"next_route\" set to one of the following options:\n",
    "      - \"call_llm\" for additional financial analysis,\n",
    "      - \"web_research\" for further web research,\n",
    "      - \"answer_normal_query\" for more normal query insights,\n",
    "      #- \"parallel_branches\" to combine branches again.\n",
    "    If no additional insights are needed, return \"done\".\n",
    "    \n",
    "    For example:\n",
    "    {{\"next_route\": \"call_llm\"}}\n",
    "    \"\"\"\n",
    "    result = llm.invoke(prompt)\n",
    "    output_text = result.content.strip()\n",
    "    try:\n",
    "        decision = json.loads(output_text)\n",
    "        next_route = decision.get(\"next_route\", \"done\")\n",
    "    except Exception as e:\n",
    "        print(\"Error in evaluation_decision:\", e)\n",
    "        next_route = \"done\"\n",
    "    # Optionally update state with next_route\n",
    "    state[\"next_route\"] = next_route\n",
    "    return {\"next_route\": next_route}\n",
    "\n",
    "def get_route(state: State) -> str:\n",
    "    return state[\"route\"]\n",
    "\n",
    "def call_route_first_step(state: State):\n",
    "    # Debug print\n",
    "    print(f\"Checking for image in state: {bool(state.get('image') and len(state['image']) > 0)}\")\n",
    "    print(f\"Image processed status: {state.get('image_processed', False)}\")\n",
    "    \n",
    "    # Make sure to check the flag explicitly\n",
    "    image_processed = state.get(\"image_processed\", False)\n",
    "    # Only route to image analysis if we have an image AND it's not been processed\n",
    "    if state.get(\"image\") and len(state[\"image\"]) > 0 and not image_processed:\n",
    "        print(\"Routing to Image_Analysis\")\n",
    "        return {\"route\": \"Image_Analysis\"}\n",
    "    \n",
    "    # Otherwise proceed with regular routing\n",
    "    router_response = llm.with_structured_output(Route_First_Step).invoke(state[\"research_topic\"])\n",
    "    print('Image Analysis Done, now proceeding with regular routing, which is: ', router_response.step)\n",
    "    print(f\"Regular routing result: {router_response.step}\")\n",
    "    return {\"route\": router_response.step}\n",
    "\n",
    "def validate_state_transition(old_state: State, new_state: State):\n",
    "    required_fields = set(State.__annotations__.keys())\n",
    "    missing = required_fields - set(new_state.keys())\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing state updates for: {missing}\")\n",
    "    return True\n",
    "\n",
    "def after_image_analysis(state):\n",
    "    return {**state}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gemma3(state: State):\n",
    "    \"\"\"Process image using Gemma 3 model and save the response.\"\"\"\n",
    "    print(\"Inside call_gemma3 function\")\n",
    "    try:\n",
    "        image_path = state[\"image\"][0]\n",
    "        with open(\"C:\\Disk D\\Semester 4 2\\LLMs\\Financial_Agent\\Screenshot 2025-03-14 115707.png\", \"rb\") as f:\n",
    "            image_b64 = base64.b64encode(f.read()).decode()\n",
    "\n",
    "        assert len(image_b64) < 180_000, \\\n",
    "            \"To upload larger images, use the assets API (see docs)\"\n",
    "        \n",
    "        \n",
    "        # Use a simpler approach with the standard LLM as a fallback\n",
    "        try:\n",
    "            # Try Gemma API first\n",
    "            invoke_url = \"https://integrate.api.nvidia.com/v1/chat/completions\"\n",
    "            headers = {\n",
    "                \"Authorization\": \"Bearer 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\",\n",
    "                \"Accept\": \"application/json\"\n",
    "            }\n",
    "            \n",
    "            payload = {\n",
    "                \"model\": \"google/gemma-3-27b-it\",\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"Describe what you see in this image. Focus on any charts, financial data, or technical analysis elements if present.\\n<img src=\\\"data:image/png;base64,{image_b64}\\\" />\"\n",
    "                    }\n",
    "                ],\n",
    "                \"max_tokens\": 512,\n",
    "                \"temperature\": 0.20,\n",
    "                \"top_p\": 0.70,\n",
    "                \"stream\": False\n",
    "            }\n",
    "            \n",
    "            print(\"Sending request to Gemma API...\")\n",
    "            gemma_response = requests.post(invoke_url, headers=headers, json=payload)\n",
    "            gemma_response.raise_for_status()  # Raise exception for HTTP errors\n",
    "            \n",
    "            data = gemma_response.json()\n",
    "            if \"choices\" in data and data[\"choices\"]:\n",
    "                full_response = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "                print(f\"Got response from Gemma API: {full_response[:100]}...\")\n",
    "            else:\n",
    "                raise ValueError(\"No valid response content from Gemma API\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Gemma API error: {str(e)}. Using fallback method.\")\n",
    "            # Use local LLM as fallback\n",
    "            fallback_prompt = f\"Describe what you see in this image. The image appears to be a financial chart or technical analysis pattern graph from Investopedia. Please describe the patterns, trends, and elements visible in the chart.\"\n",
    "            full_response = llm.invoke(fallback_prompt).content\n",
    "            print(f\"Got fallback response: {full_response[:100]}...\")\n",
    "        \n",
    "        # Format the response as Markdown\n",
    "        markdown_response = f\"## Image Analysis Results\\n\\n{full_response}\"\n",
    "        \n",
    "        # Add the response to messages\n",
    "        updated_messages = state[\"messages\"] + [HumanMessage(content=markdown_response)]\n",
    "        state['image_processed'] = True\n",
    "        # Use the main LLM to determine the next route\n",
    "        route_prompt = \"Based on the image analysis of what appears to be a financial chart or technical analysis pattern, what should be the next step? Choose one: Web_query, Normal_query, Financial_Analysis, YouTube_Recommender\"\n",
    "        try:\n",
    "            next_route = llm.invoke(route_prompt).content.strip()\n",
    "            # Extract just the route name if there's additional text\n",
    "            for route in [\"Web_query\", \"Normal_query\", \"Financial_Analysis\", \"YouTube_Recommender\"]:\n",
    "                if route in next_route:\n",
    "                    next_route = route\n",
    "                    break\n",
    "            else:\n",
    "                next_route = \"Normal_query\"  # Default\n",
    "        except:\n",
    "            next_route = \"Normal_query\"  # Default on error\n",
    "            \n",
    "        print(f\"Setting next route to: {next_route}\")\n",
    "        \n",
    "        # Set image_processed flag to True and provide the next route\n",
    "        return {\n",
    "            \"running_summary\": markdown_response,\n",
    "            \"messages\": updated_messages,\n",
    "            \"image_processed\": True,  # This is correctly set here\n",
    "            \"route\": next_route,\n",
    "            # Make sure to include other needed state variables that should be preserved\n",
    "            \"research_topic\": state[\"research_topic\"],\n",
    "            \"search_query\": state.get(\"search_query\", \"\"),\n",
    "            \"web_research_results\": state.get(\"web_research_results\", []),\n",
    "            \"sources_gathered\": state.get(\"sources_gathered\", []),\n",
    "            \"research_loop_count\": state.get(\"research_loop_count\", 0),\n",
    "            \"image\": state[\"image\"]  # Important to maintain the image reference\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Similar update for the error case...\n",
    "        return {\n",
    "            # All the same state variables need to be preserved here as well\n",
    "            \"running_summary\": str(e),\n",
    "            \"messages\": state[\"messages\"] + [HumanMessage(content=str(e))],\n",
    "            \"image_processed\": True,\n",
    "            \"route\": \"Normal_query\",\n",
    "            \"research_topic\": state[\"research_topic\"],\n",
    "            \"search_query\": state.get(\"search_query\", \"\"),\n",
    "            \"web_research_results\": state.get(\"web_research_results\", []),\n",
    "            \"sources_gathered\": state.get(\"sources_gathered\", []),\n",
    "            \"research_loop_count\": state.get(\"research_loop_count\", 0),\n",
    "            \"image\": state[\"image\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_router():\n",
    "    final_router = StateGraph(State)\n",
    "    \n",
    "    # Add all nodes\n",
    "    final_router.add_node(\"route_first_step\", call_route_first_step)\n",
    "    final_router.add_node(\"generate_query\", generate_query)\n",
    "    final_router.add_node(\"web_research\", web_research)\n",
    "    final_router.add_node(\"summarize_sources\", summarize_sources)\n",
    "    final_router.add_node(\"reflect_on_summary\", reflect_on_summary)\n",
    "    final_router.add_node(\"finalize_summary\", finalize_summary)\n",
    "    final_router.add_node('call_llm', call_llm)\n",
    "    final_router.add_node('take_action', take_action)\n",
    "    final_router.add_node('format_financial_analysis', format_financial_analysis)\n",
    "    final_router.add_node('answer_normal_query', answer_normal_query)\n",
    "    final_router.add_node('youtube_recommend', youtube_recommend)\n",
    "    final_router.add_node(\"self_evaluate_final\", evaluate_response)\n",
    "    final_router.add_node(\"evaluation_decision\", evaluation_decision)\n",
    "    # Add the new image processing node\n",
    "    final_router.add_node(\"image_analysis\", call_gemma3)\n",
    "    \n",
    "    # Define connections\n",
    "    final_router.add_edge(START, \"route_first_step\")\n",
    "    \n",
    "    # Update conditional edges to include Image_Analysis route\n",
    "    final_router.add_conditional_edges(\"route_first_step\", get_route, {\n",
    "        'Image_Analysis': 'image_analysis',\n",
    "        'Web_query': 'generate_query',\n",
    "        'Normal_query': 'answer_normal_query',\n",
    "        'Financial_Analysis': 'call_llm',\n",
    "        'YouTube_Recommender': 'youtube_recommend'\n",
    "    })\n",
    "    \n",
    "    # Add edge from image_analysis to subsequent routing\n",
    "    final_router.add_edge(\"image_analysis\", \"route_first_step\")\n",
    "    \n",
    "    final_router.add_edge(\"answer_normal_query\", 'self_evaluate_final')\n",
    "    \n",
    "    final_router.add_conditional_edges(\n",
    "        \"call_llm\",\n",
    "        exists_action,\n",
    "        {True: \"take_action\", False: \"format_financial_analysis\"}\n",
    "    )\n",
    "    final_router.add_edge(\"take_action\", \"format_financial_analysis\")\n",
    "    final_router.add_edge(\"format_financial_analysis\", END)\n",
    "    \n",
    "    final_router.add_edge(\"generate_query\", \"web_research\")\n",
    "    final_router.add_edge(\"web_research\", \"summarize_sources\")\n",
    "    final_router.add_edge(\"summarize_sources\", \"reflect_on_summary\")\n",
    "    final_router.add_conditional_edges(\"reflect_on_summary\", route_research)\n",
    "    final_router.add_edge(\"finalize_summary\", 'self_evaluate_final')\n",
    "    final_router.add_edge(\"self_evaluate_final\", 'evaluation_decision')\n",
    "    \n",
    "    final_router.add_conditional_edges(\"evaluation_decision\", lambda x: x.get(\"next_route\", \"done\"), {\n",
    "        'done': END,\n",
    "        'call_llm': 'call_llm',\n",
    "        'web_research': 'web_research',\n",
    "        'answer_normal_query': 'answer_normal_query',\n",
    "        'YouTube_Recommender': 'youtube_recommend'\n",
    "    })\n",
    "    final_router.add_edge(\"youtube_recommend\", END)\n",
    "    \n",
    "    return final_router.compile()\n",
    "\n",
    "# Update the create_initial_state function to better handle images\n",
    "def create_initial_state(user_query: str, image: list[str] = []) -> State:\n",
    "    return {\n",
    "        \"route\": None,\n",
    "        \"research_topic\": user_query,\n",
    "        \"search_query\": \"\",\n",
    "        \"web_research_results\": [],\n",
    "        \"sources_gathered\": [],\n",
    "        \"research_loop_count\": 0,\n",
    "        \"running_summary\": \"\",\n",
    "        \"image\": image,\n",
    "        \"messages\": [HumanMessage(content=user_query)]\n",
    "    }\n",
    "\n",
    "class Route_First_Step(BaseModel):\n",
    "    step: Literal['Web_query', 'Normal_query', 'Financial_Analysis', 'YouTube_Recommender'] = Field(\n",
    "        None,\n",
    "        description='Determine whether to perform a web search, answer a normal question, perform a financial analysis or recommend YouTube videos'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
